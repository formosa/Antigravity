"""
LLM Context Generator for Sphinx-Needs Documentation.

This script transforms the Sphinx-Needs JSON export (`needs.json`) into a
flattened Markdown document optimized for LLM context injection. The output
provides a hierarchical, human-readable summary of all requirements,
specifications, and design elements.

Purpose
-------
Generate a single Markdown file (`context_flat.md`) containing all
Sphinx-Needs items, organized by document hierarchy:

1. BRD (Business Requirements)
2. NFR (Constraints)
3. FSD (Specifications)
4. SAD (Architecture)
5. ICD (Data Contracts)
6. TDD (Design Blueprints)
7. ISP (Test Prompts)

Dependencies
------------
- Python 3.8+
- `needs.json` : Generated by `sphinx-build -b needs docs docs/_build`

Usage
-----
Command-line execution::

    python generate_llm_context.py <needs_json_path> <output_md_path>

Example::

    python generate_llm_context.py docs/_build/json/needs.json docs/llm_export/context_flat.md

Workflow Integration::

    # Referenced by:
    # - .agent/workflows/update_documentation_spec.md
    # - .agent/workflows/traceability_audit.md
    # - .agent/tools/rebuild_docs.mdt

Output Format
-------------
The generated Markdown follows this structure::

    # Maggie Application Framework - Context Dump
    > **Format:** Flattened Hierarchy. Optimized for LLM Context.

    ## 1. REQUIREMENTS (BRD)
    ### [Section Name]
    **[BRD-1] Title** -> NFR-1, FSD-2
    Description text...

Notes
-----
- Items are sorted hierarchically by prefix, then numerically by ID
- Links are displayed inline with arrow notation (`->`)
- Section headers are derived from `section_name` field in needs.json

See Also
--------
- Sphinx-Needs JSON schema: https://sphinx-needs.readthedocs.io/en/latest/builders.html
- docs/conf.py : Sphinx configuration with `needs_build_json = True`
"""
import json
import os
import sys


def generate_context(needs_json_path, output_md_path):
    """
    Transform needs.json into flattened Markdown for LLM context.

    Reads the Sphinx-Needs JSON export and generates a hierarchically
    organized Markdown document suitable for injection into LLM prompts.

    Parameters
    ----------
    needs_json_path : str
        Absolute or relative path to the `needs.json` file generated
        by Sphinx-Needs (typically `docs/_build/json/needs.json`).
    output_md_path : str
        Destination path for the generated Markdown file
        (typically `docs/llm_export/context_flat.md`).

    Returns
    -------
    None
        Writes output directly to `output_md_path`.

    Raises
    ------
    SystemExit
        If `needs_json_path` does not exist.

    Examples
    --------
    >>> generate_context('docs/_build/json/needs.json', 'context.md')
    Loading docs/_build/json/needs.json...
    Processing 220 requirements...
    Context written to context.md
    """
    print(f'Loading {needs_json_path}...')
    try:
        with open(needs_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print("Error: needs.json not found. Run sphinx-build first.")
        sys.exit(1)

    needs = data.get('versions', {}).get('0.1', {}).get('needs', {})

    # Sort by ID (Hierarchical sort: BRD < NFR < FSD etc)
    # Define Section Order
    section_order = {
        'BRD': 0, 'req': 0,
        'NFR': 1, 'constraint': 1,
        'FSD': 2, 'spec': 2,
        'SAD': 3, 'arch': 3,
        'ICD': 4, 'schema': 4,
        'TDD': 5, 'impl': 5,
        'ISP': 6, 'test': 6
    }

    def sort_key(n_id):
        prefix = n_id.split('-')[0]
        # order index
        idx = section_order.get(prefix, 99)
        # numeric part
        try:
            num_part = n_id.split('-')[1]
            parts = [int(p) for p in num_part.split('.')]
            return [idx] + parts
        except:
            return [idx, 999]

    sorted_ids = sorted(needs.keys(), key=sort_key)

    print(f'Processing {len(sorted_ids)} requirements...')

    with open(output_md_path, 'w', encoding='utf-8') as out:
        out.write('# Maggie Application Framework - Context Dump\n')
        out.write('> **Format:** Flattened Hierarchy. Optimized for LLM Context.\n\n')

        current_section_idx = -1
        current_sub_section = ""
        section_names = ["1. REQUIREMENTS (BRD)", "2. CONSTRAINTS (NFR)", "3. SPECIFICATIONS (FSD)", "4. ARCHITECTURE (SAD)", "5. DATA CONTRACTS (ICD)", "6. DESIGN BLUEPRINTS (TDD)", "7. TEST PROMPTS (ISP)"]

        for n_id in sorted_ids:
            item = needs[n_id]
            prefix = n_id.split('-')[0]
            s_idx = section_order.get(prefix, -1)

            # Top-level Section Header
            if s_idx != current_section_idx and s_idx < len(section_names):
                if s_idx >= 0:
                    out.write(f'\n## {section_names[s_idx]}\n\n')
                current_section_idx = s_idx
                current_sub_section = "" # Reset sub-section on new top-level section

            # Sub-section Header (original RST sections)
            sub_section = item.get('section_name', '')
            if sub_section and sub_section != current_sub_section:
                out.write(f'### {sub_section}\n\n')
                current_sub_section = sub_section

            # Render Item
            # ID | Type | Title
            # Description
            # Links: ...

            title = item.get('title', '')
            desc = item.get('content', '')
            links = item.get('links', [])

            # Format:
            # **[ID] Title** (Links: ...)
            # Description

            link_str = f" -> {', '.join(links)}" if links else ""

            out.write(f'**[{n_id}] {title}**{link_str}\n')
            if desc:
                out.write(f'{desc}\n')
            out.write('\n')

    print(f'Context written to {output_md_path}')

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("Usage: generate_llm_context.py <json_path> <output_path>")
        sys.exit(1)

    generate_context(sys.argv[1], sys.argv[2])
