
## 8. Practical Application Guidelines

### 8.1 New Feature Workflow

**Scenario:** Add "Voice Sentiment Analysis" feature

**Step 1: BRD (Business Justification)**

~~~rst
.. brd:: Sentiment-Aware Responses
   :id: BRD-10

   Enable context-aware emotional intelligence to improve user satisfaction and engagement metrics (target: 25% increase in session duration).

~~~

**Step 2: NFR (Constraints)**

~~~rst
.. nfr:: Sentiment Analysis Constraints
   :id: NFR-9
   :links: BRD-10

.. nfr:: CPU-based inference (max 50ms latency per audio chunk).
   :id: NFR-9.1
   :links: NFR-9

.. nfr:: Model size <100MB (fits in system RAM).
   :id: NFR-9.2
   :links: NFR-9

.. nfr:: Accuracy: F1 score ≥ 0.75 on IEMOCAP dataset.
   :id: NFR-9.3
   :links: NFR-9

~~~

**Step 3: FSD (Behavior)**

~~~rst
.. fsd:: Sentiment Detection Pipeline
   :id: FSD-10
   :links: NFR-9

.. fsd:: Audio Service extracts prosodic features (pitch, energy).
   :id: FSD-10.1
   :links: FSD-10

.. fsd:: Sentiment classifier runs asynchronously (non-blocking).
   :id: FSD-10.2
   :links: FSD-10

.. fsd:: Results tagged to request_id, sent to Core.
   :id: FSD-10.3
   :links: FSD-10

.. fsd:: LLM Service receives sentiment context in prompt metadata.
   :id: FSD-10.4
   :links: FSD-10

~~~

**Step 4: SAD (Architecture)**

~~~rst
.. sad:: Asynchronous Sentiment Processing
   :id: SAD-7
   :links: FSD-10.2

.. sad:: Pattern: Fire-and-forget PUSH (Audio) → PULL (Core).
   :id: SAD-7.1
   :links: SAD-7

.. sad:: No blocking on sentiment result (best-effort enrichment).
   :id: SAD-7.2
   :links: SAD-7

~~~

**Step 5: ICD (Contracts)**

~~~rst
.. icd:: Sentiment Metadata Schema
   :id: ICD-6
   :links: SAD-7.1

   .. code-block:: json

      {
        "request_id": "uuid-v4",
        "sentiment": {
          "label": "neutral" | "positive" | "negative" | "unknown",
          "confidence": 0.0-1.0,
          "valence": -1.0 to +1.0,
          "arousal": 0.0 to 1.0
        }
      }

~~~

**Step 6: TDD (Component Design)**

~~~rst
.. tdd:: Component: SentimentClassifier
   :id: TDD-5
   :links: ICD-6

.. tdd:: Class: SentimentClassifier (runs in Audio Process).
   :id: TDD-5.1
   :links: TDD-5

.. tdd:: Dependencies: librosa, numpy, onnxruntime (CPU).
   :id: TDD-5.2
   :links: TDD-5

.. tdd:: Method: analyze(audio_chunk: np.ndarray) -> Dict.
   :id: TDD-5.3
   :links: TDD-5

.. tdd:: Internal: ONNX model loaded on init (<100MB per NFR-9.2).
   :id: TDD-5.4
   :links: TDD-5

~~~

**Step 7: ISP (Code Stub)**

~~~python
# |ISP-6|: "Sentiment Classifier Implementation Stub"

import numpy as np
import onnxruntime as ort

class SentimentClassifier:
    """
    CPU-based sentiment analysis from audio prosody.

    Implements
    ----------
    |TDD-5|, |FSD-10|

    Constraints
    -----------
    |NFR-9.1|: Max 50ms latency
    |NFR-9.2|: Model <100MB
    """

    def __init__(self, model_path: str):
        """
        Load ONNX model for CPU inference.

        Parameters
        ----------
        model_path : str
            Path to sentiment.onnx (<100MB per |NFR-9.2|)

        References
        ----------
        |TDD-5.4|
        """
        pass

    def analyze(self, audio_chunk: np.ndarray) -> dict:
        """
        Extract sentiment from audio prosody.

        Parameters
        ----------
        audio_chunk : np.ndarray
            PCM audio (16kHz, mono)

        Returns
        -------
        dict
            Sentiment metadata per |ICD-6| schema

        References
        ----------
        |FSD-10.1|, |NFR-9.1|
        """
        pass

~~~

### 8.2 Refactoring Existing Documentation

**Scenario:** Discovered `FSD-4.4` incorrectly specifies GPU-based VAD, violating `NFR-1.1` (CPU-only Audio)

**Step 1: Identify Conflict**

~~~rst
.. nfr:: CPU: AMD Ryzen 9 5900X (Audio/Core must run here).
   :id: NFR-1.1

.. fsd:: VAD (Stage 2): Silero via ONNX Runtime GPU.
   :id: FSD-4.4
   :links: NFR-1.1 (CONFLICT)

~~~

**Step 2: Mark Dirty**

~~~rst
.. reconciliation_manifest (FSD):
   :integrity_status: "DIRTY"
   :pending_items:
     - target_tag: "FSD-4.4"
       source_trigger: "NFR-1.1"
       issue_type: "CONSTRAINT_VIOLATION"
       description: "FSD-4.4 specifies GPU inference but NFR-1.1 restricts Audio Process to CPU only."

~~~

**Step 3: Resolve Conflict**

**Option A: Move to Runtime Process (Architecture Change)**

~~~rst
.. fsd:: VAD (Stage 2): Silero via ONNX Runtime GPU in Runtime Process. Audio sends raw buffer to Core for routing.
   :id: FSD-4.4 (REVISED)
   :links: NFR-1.2

.. sad:: Audio-to-Runtime VAD Pipeline
   :id: SAD-8

.. sad:: Audio (webrtcvad) → Core → Runtime (Silero) → Core.
   :id: SAD-8.1
   :links: SAD-8

.. sad:: Adds 10-20ms IPC overhead (acceptable per NFR-4.2).
   :id: SAD-8.2
   :links: SAD-8

~~~

**Option B: Use CPU-based Silero (Simpler)**

~~~rst
.. fsd:: VAD (Stage 2): Silero via ONNX Runtime CPU. Runs locally in Audio Process.
   :id: FSD-4.4 (REVISED)
   :links: NFR-1.1, BRD-5.2

.. nfr:: Silero VAD CPU Latency: <30ms per chunk.
   :id: NFR-9.4

~~~

**Step 4: Cascade Updates**

~~~rst
.. tdd:: Audio Process: ONNX Runtime CPU session for Silero.
   :id: TDD-2.X (UPDATE)

.. icd:: Remove GPU memory allocation from audio config.
   :id: ICD-X (UPDATE)

.. reconciliation_status:: CLEAN reconciliation_manifest.

~~~

----------
