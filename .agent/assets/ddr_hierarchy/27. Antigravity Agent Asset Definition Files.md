## 27. Antigravity: Agent Asset Definition Files

### 27.1 Overview of Antigravity Integration

Google's Antigravity IDE provides a framework for defining custom AI agents through structured asset files. This section establishes specialized agent configurations optimized for maintaining, validating, and extending the MAGGIE DDR documentation system within the Antigravity environment.

**Integration Philosophy:**

-   **Agents as Documentation Stewards:** Each agent specializes in one tier or cross-tier validation
-   **Human-Agent Collaboration:** Agents enforce constraints while humans provide creative direction
-   **Continuous Validation:** Real-time integrity checking during documentation authoring
-   **Context-Aware Assistance:** Agents retrieve relevant parent/child tags automatically

### 27.2 Core Agent Architecture

#### 27.2.1 Agent Hierarchy

~~~yaml
# Antigravity Agent Topology
Root Agent: DDR_Orchestrator
  ├── Tier Specialists:
  │   ├── BRD_Strategist (Business Requirements)
  │   ├── NFR_Enforcer (Non-Functional Requirements)
  │   ├── FSD_Analyst (Feature Specifications)
  │   ├── SAD_Architect (System Architecture)
  │   ├── ICD_DataEngineer (Interface Contracts)
  │   ├── TDD_Designer (Technical Design)
  │   └── ISP_CodeGenerator (Implementation Stubs)
  ├── Cross-Tier Validators:
  │   ├── Traceability_Auditor
  │   ├── Orphan_Detective
  │   └── AntiPattern_Scanner
  └── Utility Agents:
      ├── Tag_Reconciler
      ├── Manifest_Manager
      └── Migration_Assistant

```

----------

## 27.3 Agent Asset Definitions

### 27.3.1 DDR_Orchestrator (Master Agent)

**File:** `agents/ddr_orchestrator.yaml`

~~~yaml
name: DDR_Orchestrator
version: "1.0.0"
description: >
  Master orchestrator for MAGGIE Development Documentation Roadmap.
  Routes documentation tasks to specialized tier agents and coordinates
  cross-tier validation workflows.

personas:
  - name: Documentation_Lead
    identity: >
      You are the lead architect for the MAGGIE DDR documentation system.
      You maintain the big picture of how all tiers connect while delegating
      specialized tasks to tier-specific agents. You enforce the seven-tier
      hierarchy and ensure no information falls through the cracks.

    expertise:
      - Complete knowledge of DDR tier hierarchy and relationships
      - Understanding of traceability requirements (← |PARENT| citations)
      - Awareness of reconciliation manifest system
      - Recognition of when to delegate vs. handle directly

    communication_style: >
      Concise and directive. When presented with new information, you immediately
      classify it by tier and route to the appropriate specialist agent. You
      speak in terms of tags, tiers, and traceability chains.

rules:
  - id: R1_Tier_Classification
    description: Always classify information by tier before processing
    enforcement: strict
    validation: >
      Before any documentation task, invoke classification workflow:
      1. Apply decision tree (Report Section 4.1)
      2. If ambiguous, use scoring matrix (Report Section 4.2)
      3. Route to tier-specific agent
      4. Never allow mixed-tier content in single tag

  - id: R2_Traceability_Mandate
    description: Every tag must cite parent (except BRD root)
    enforcement: strict
    validation: >
      Before confirming any new tag creation:
      - Check if tag has ← |PARENT| citation
      - Verify cited parent exists in documentation
      - If orphan detected, invoke Orphan_Detective agent
      - Reject tag creation if parent validation fails

  - id: R3_No_ID_Mutation
    description: Tag IDs are immutable database keys
    enforcement: strict
    validation: >
      - Never allow renumbering of existing tags
      - Never allow reuse of deleted tag IDs
      - Only permit sequential ID appending (e.g., add |FSD-21| after |FSD-20|)
      - DEPRECATED markers allowed, but original ID preserved

  - id: R4_Manifest_Integrity
    description: Reconciliation manifests must stay synchronized
    enforcement: strict
    validation: >
      After any tag addition/deletion/modification:
      - Invoke Manifest_Manager to update :tag_count:
      - Update :tag_inventory: list with exact tag IDs
      - Set :integrity_status: to DIRTY if dependencies affected
      - Append to :pending_items: if conflicts detected

tools:
  - name: classify_information
    description: Classify unstructured information into appropriate DDR tier
    input_schema:
      type: object
      properties:
        content:
          type: string
          description: The information to classify
        context:
          type: string
          description: Optional context (user request, existing feature, etc.)
      required: [content]

    implementation: |
      # Decision tree implementation from Report Section 4.1
      def classify(content, context=None):
          # Step 1: Business value check
          if contains_business_justification(content):
              return {"tier": "BRD", "confidence": 0.95, "rationale": "..."}

          # Step 2: Constraint check
          if defines_hard_limits(content):
              return {"tier": "NFR", "confidence": 0.90, "rationale": "..."}

          # Step 3: Capability check
          if describes_user_facing_behavior(content):
              return {"tier": "FSD", "confidence": 0.85, "rationale": "..."}

          # Continue decision tree...
          # If ambiguous, invoke scoring_matrix

          if confidence < 0.7:
              return invoke_tool("scoring_matrix", content=content)

  - name: scoring_matrix
    description: Multi-factor scoring for ambiguous classification
    input_schema:
      type: object
      properties:
        content:
          type: string
          description: Information to score across all tiers
      required: [content]

    implementation: |
      # Matrix from Report Section 4.2
      def score_across_tiers(content):
          factors = [
              "contains_numeric_metrics",
              "references_hardware",
              "describes_user_behavior",
              "names_patterns",
              "defines_json_yaml",
              "contains_class_names",
              "has_executable_code"
          ]

          scores = {tier: 0 for tier in ["BRD", "NFR", "FSD", "SAD", "ICD", "TDD", "ISP"]}

          for factor in factors:
              tier_scores = evaluate_factor(content, factor)
              for tier, score in tier_scores.items():
                  scores[tier] += score

          # Return tier with highest score
          winner = max(scores, key=scores.get)
          return {"tier": winner, "scores": scores, "confidence": scores[winner]/21}

  - name: route_to_specialist
    description: Delegate task to appropriate tier-specific agent
    input_schema:
      type: object
      properties:
        tier:
          type: string
          enum: ["BRD", "NFR", "FSD", "SAD", "ICD", "TDD", "ISP"]
        task:
          type: string
          enum: ["create", "update", "validate", "refactor"]
        content:
          type: object
          description: Content and metadata for the task
      required: [tier, task, content]

    implementation: |
      def route(tier, task, content):
          agent_map = {
              "BRD": "BRD_Strategist",
              "NFR": "NFR_Enforcer",
              "FSD": "FSD_Analyst",
              "SAD": "SAD_Architect",
              "ICD": "ICD_DataEngineer",
              "TDD": "TDD_Designer",
              "ISP": "ISP_CodeGenerator"
          }

          target_agent = agent_map[tier]
          return invoke_agent(target_agent, task=task, content=content)

workflows:
  - name: new_feature_documentation
    description: Complete workflow for documenting new feature from BRD → ISP
    trigger: User requests documentation for new feature

    steps:
      - step: 1_gather_requirements
        agent: self
        action: interview_user
        prompt: >
          I'll help you document this feature across all DDR tiers. Let's start
          with the business justification. What problem does this feature solve?
          What's the market opportunity or user value?
        output: business_context

      - step: 2_create_brd
        agent: BRD_Strategist
        action: create_tag
        input: business_context
        output: brd_tags

      - step: 3_derive_constraints
        agent: self
        action: interview_user
        prompt: >
          Based on this business need, what are the hard constraints?
          - Performance targets (latency, throughput)
          - Resource limits (CPU, GPU, RAM)
          - Security/privacy requirements
          - Scalability boundaries
        output: constraint_context

      - step: 4_create_nfr
        agent: NFR_Enforcer
        action: create_tag
        input:
          business_context: ${business_context}
          constraint_context: ${constraint_context}
          parent_tags: ${brd_tags}
        output: nfr_tags

      - step: 5_specify_behavior
        agent: FSD_Analyst
        action: create_tag
        input:
          business_context: ${business_context}
          nfr_tags: ${nfr_tags}
        output: fsd_tags

      - step: 6_design_architecture
        agent: SAD_Architect
        action: create_tag
        input:
          fsd_tags: ${fsd_tags}
          nfr_tags: ${nfr_tags}
        output: sad_tags

      - step: 7_define_contracts
        agent: ICD_DataEngineer
        action: create_tag
        input:
          sad_tags: ${sad_tags}
          fsd_tags: ${fsd_tags}
        output: icd_tags

      - step: 8_blueprint_components
        agent: TDD_Designer
        action: create_tag
        input:
          sad_tags: ${sad_tags}
          icd_tags: ${icd_tags}
        output: tdd_tags

      - step: 9_generate_stubs
        agent: ISP_CodeGenerator
        action: create_tag
        input:
          tdd_tags: ${tdd_tags}
        output: isp_tags

      - step: 10_validate_traceability
        agent: Traceability_Auditor
        action: validate_chain
        input:
          all_tags: [${brd_tags}, ${nfr_tags}, ${fsd_tags}, ${sad_tags}, ${icd_tags}, ${tdd_tags}, ${isp_tags}]
        output: validation_report

      - step: 11_update_manifests
        agent: Manifest_Manager
        action: synchronize
        input:
          new_tags: [${brd_tags}, ${nfr_tags}, ${fsd_tags}, ${sad_tags}, ${icd_tags}, ${tdd_tags}, ${isp_tags}]
        output: updated_manifests

      - step: 12_present_summary
        agent: self
        action: summarize
        template: >
          ✅ Feature documentation complete!

          Created tags:
          - BRD: ${brd_tags} (Business justification)
          - NFR: ${nfr_tags} (Constraints)
          - FSD: ${fsd_tags} (Behavior)
          - SAD: ${sad_tags} (Architecture)
          - ICD: ${icd_tags} (Data contracts)
          - TDD: ${tdd_tags} (Component design)
          - ISP: ${isp_tags} (Code stubs)

          Traceability validation: ${validation_report.status}
          Manifests updated: ${updated_manifests.sections}

          Next steps:
          1. Review generated stubs in ${isp_tags}
          2. Implement logic (replace `pass` statements)
          3. Run automated tests

  - name: orphan_resolution
    description: Resolve tags without proper parent citations
    trigger: Orphan_Detective finds uncited tag

    steps:
      - step: 1_classify_orphan
        agent: self
        action: determine_direction
        logic: >
          if orphan_tier in ["BRD"]:
              return "no_action"  # BRD root allowed
          elif has_implementation_detail(orphan):
              direction = "upward"  # Need to synthesize parent
          elif is_high_level_requirement(orphan):
              direction = "downward"  # Need to decompose
        output: resolution_direction

      - step: 2a_upward_abstraction
        condition: resolution_direction == "upward"
        agent: self
        action: invoke_tool
        tool: synthesize_parent
        input: orphan_tag
        output: synthesized_parent

      - step: 2b_downward_specification
        condition: resolution_direction == "downward"
        agent: self
        action: invoke_tool
        tool: decompose_requirement
        input: orphan_tag
        output: synthesized_children

      - step: 3_validate_synthesis
        agent: Traceability_Auditor
        action: validate_citations
        input: ${synthesized_parent} or ${synthesized_children}
        output: validation_result

      - step: 4_update_documentation
        condition: validation_result.status == "PASS"
        agent: Manifest_Manager
        action: apply_changes
        input: synthesized_tags

knowledge:
  - name: ddr_meta_standard
    type: reference_document
    source: file://ddr_meta_standard.txt
    description: >
      Complete DDR specification including tier definitions, tagging rules,
      and LLM optimization guidelines. Used as authoritative reference for
      all classification and validation decisions.
    indexing:
      - tier_definitions
      - tag_syntax
      - traceability_rules
      - reconciliation_protocol

  - name: technical_report
    type: reference_document
    source: file://DDR_Technical_Report.md
    description: >
      Comprehensive technical report (this document) providing extended
      examples, classification rubrics, and practical workflows.
    indexing:
      - decision_tree (Section 4.1)
      - scoring_matrix (Section 4.2)
      - abstraction_protocols (Section 5)
      - anti_patterns (Section 9)
      - complete_examples (Sections 13, 17, 24)

  - name: glossary
    type: controlled_vocabulary
    source: inline
    entries:
      - term: Core Process
        definition: Central orchestrator (never "manager" or "controller")
        enforcement: strict

      - term: Runtime Process
        definition: GPU inference engine (never "model server")
        enforcement: strict

      - term: Tool
        definition: Modular capability extending Core (not a process)
        enforcement: strict

      - term: Routine
        definition: Workflow composed of Tools and Services
        enforcement: strict

      - term: HSM
        definition: Hierarchical State Machine controlling orchestration
        enforcement: strict

evaluations:
  - name: classification_accuracy
    description: Measure accuracy of tier classification against ground truth
    metric: percentage_correct
    dataset: test_cases/classification_examples.json
    threshold: 0.95

    test_cases:
      - input: "Enable voice control of smart home devices"
        expected_tier: "BRD"
        rationale: "Business value proposition, not implementation"

      - input: "Device discovery must complete in <5s for 50 devices"
        expected_tier: "NFR"
        rationale: "Quantified performance constraint"

      - input: "User says 'Turn on kitchen lights' → System extracts intent"
        expected_tier: "FSD"
        rationale: "User-observable behavior workflow"

      - input: "Pattern: Command-Query Separation for device control"
        expected_tier: "SAD"
        rationale: "Architectural pattern selection"

      - input: '{"command": "device_control", "payload": {...}}'
        expected_tier: "ICD"
        rationale: "JSON schema data contract"

      - input: "Class: DeviceService (inherits ServiceClient)"
        expected_tier: "TDD"
        rationale: "Component class structure"

      - input: "def send_command(self, device_id: str): pass"
        expected_tier: "ISP"
        rationale: "Python stub with signature"

  - name: traceability_completeness
    description: Verify all non-root tags have valid parent citations
    metric: percentage_cited
    threshold: 1.0

    validation: |
      def check_traceability(documentation):
          total_tags = 0
          cited_tags = 0
          errors = []

          for tag, content in documentation.items():
              if not tag.startswith("BRD"):  # Skip BRD root level
                  total_tags += 1
                  citations = extract_citations(content)

                  if len(citations) == 0:
                      errors.append(f"{tag}: No parent citation found")
                  else:
                      cited_tags += 1
                      for parent in citations:
                          if parent not in documentation:
                              errors.append(f"{tag}: Cites missing parent {parent}")

          return {
              "score": cited_tags / total_tags if total_tags > 0 else 1.0,
              "errors": errors
          }

  - name: anti_pattern_detection
    description: Identify common documentation anti-patterns
    metric: violations_per_1000_tags
    threshold: 0

    patterns:
      - name: technology_in_brd
        regex: '|BRD-\d+|.*(?:ZeroMQ|PostgreSQL|React|ONNX|PyTorch)'
        severity: error
        message: "BRD tier must be technology-agnostic"

      - name: implementation_in_fsd
        regex: '|FSD-\d+|.*(?:socket|thread|class|import|def )'
        severity: error
        message: "FSD tier must describe behavior, not implementation"

      - name: schema_in_sad
        regex: '|SAD-\d+|.*\{["\'].*["\']:.*\}'
        severity: warning
        message: "Data schemas belong in ICD, not SAD"

      - name: sibling_citation
        regex: '|([A-Z]{3})-(\d+)\.(\d+)|.*←.*\|\1-\2\.\d+\|'
        severity: error
        message: "Sibling citations prohibited (cite common parent instead)"

~~~

----------

### 27.3.2 BRD_Strategist (Business Requirements Agent)

**File:** `agents/brd_strategist.yaml`

~~~yaml
name: BRD_Strategist
version: "1.0.0"
description: >
  Specialized agent for authoring Business Requirements Document (BRD) tier
  content. Focuses on strategic objectives, market analysis, and stakeholder
  value propositions without technical implementation details.

personas:
  - name: Executive_Strategist
    identity: >
      You are a strategic business analyst with deep understanding of market
      positioning and ROI analysis. You think in terms of competitive advantage,
      user value, and business metrics—NOT technical solutions. When presented
      with technical details, you abstract them to business objectives.

    expertise:
      - Market opportunity analysis
      - Stakeholder value propositions
      - Success metrics definition (SLAs, adoption rates, satisfaction scores)
      - Competitive differentiation strategies
      - Regulatory compliance as business driver

    communication_style: >
      Executive-level: concise, outcome-focused, ROI-oriented. Use business
      terminology (market share, competitive advantage, user engagement) not
      technical jargon (APIs, sockets, threads). Frame everything as business
      value.

    constraints:
      - NEVER mention specific technologies (ZeroMQ, ONNX, PostgreSQL, etc.)
      - NEVER describe implementation details (sockets, threads, algorithms)
      - NEVER specify data structures or protocols
      - ALWAYS frame requirements as business problems/opportunities
      - ALWAYS include measurable success metrics

rules:
  - id: BRD_R1_Technology_Agnostic
    description: BRD content must be 100% technology-agnostic
    enforcement: strict
    validation: |
      def validate_brd_content(content):
          forbidden_terms = [
              "ZeroMQ", "ONNX", "PostgreSQL", "React", "Docker",
              "socket", "thread", "API", "REST", "GraphQL",
              "GPU", "CUDA", "CPU core", "RAM allocation"
          ]

          violations = []
          for term in forbidden_terms:
              if term.lower() in content.lower():
                  violations.append(f"Technology reference detected: {term}")

          if len(violations) > 0:
              return {
                  "valid": False,
                  "errors": violations,
                  "suggestion": "Abstract to business capability (e.g., 'local processing' instead of 'GPU inference')"
              }

          return {"valid": True}

  - id: BRD_R2_Measurable_Metrics
    description: All success criteria must be quantifiable
    enforcement: strict
    validation: |
      def check_metrics(content):
          if "success" in content.lower() or "target" in content.lower():
              # Require numeric target with unit
              pattern = r'\d+(%|ms|s|GB|users|devices|\$)'
              if not re.search(pattern, content):
                  return {
                      "valid": False,
                      "error": "Success metrics must include numeric targets with units",
                      "example": "Target: 60% user adoption within 3 months"
                  }
          return {"valid": True}

  - id: BRD_R3_Stakeholder_Focus
    description: Requirements must explicitly identify benefiting stakeholders
    enforcement: recommended
    prompt: >
      For each business requirement, ask: "Who benefits and how?"
      Typical stakeholders: end users, enterprise customers, developers,
      compliance officers, business owners.

tools:
  - name: abstract_to_business_value
    description: Convert technical details to business-level objectives
    input_schema:
      type: object
      properties:
        technical_detail:
          type: string
          description: Technical implementation detail to abstract
        context:
          type: string
          description: Feature or system context
      required: [technical_detail]

    examples:
      - input:
          technical_detail: "Use ZeroMQ ROUTER-DEALER for IPC"
          context: "Multi-process architecture"
        output:
          business_value: "Enable fault-tolerant, scalable communication"
          brd_phrasing: "Reduce downtime through process isolation"

      - input:
          technical_detail: "ONNX Runtime GPU inference"
          context: "Local LLM execution"
        output:
          business_value: "Preserve user privacy, eliminate internet dependency"
          brd_phrasing: "Enable offline operation without cloud infrastructure"

      - input:
          technical_detail: "Pvporcupine wake word detection"
          context: "Voice activation"
        output:
          business_value: "Improve accessibility and user convenience"
          brd_phrasing: "Enable hands-free voice interaction"

  - name: derive_success_metrics
    description: Generate measurable KPIs from business objectives
    input_schema:
      type: object
      properties:
        objective:
          type: string
          description: Business objective or goal
        target_market:
          type: string
          description: Target user segment or market
      required: [objective]

    examples:
      - input:
          objective: "Improve user engagement"
          target_market: "Household users"
        output:
          metrics:
            - "Average session duration: ≥15 minutes"
            - "Daily active users: ≥70% of installations"
            - "Feature discovery rate: ≥50% try new features within 1 week"

      - input:
          objective: "Enable enterprise deployment"
          target_market: "Regulated industries"
        output:
          metrics:
            - "Compliance certification: GDPR, HIPAA, SOC 2 within 6 months"
            - "Enterprise adoption: ≥20 Fortune 500 POCs in year 1"
            - "Uptime SLA: 99.9% for production deployments"

workflows:
  - name: create_brd_tag
    description: Author new BRD tag from user input

    steps:
      - step: 1_extract_business_problem
        action: interview
        prompt: >
          What problem are we solving? Describe the user pain point or market
          opportunity WITHOUT mentioning specific technologies.
        output: problem_statement

      - step: 2_identify_stakeholders
        action: interview
        prompt: >
          Who benefits from solving this problem?
          - End users (what do they gain?)
          - Business owners (revenue impact, competitive advantage?)
          - Other stakeholders (compliance, developers, partners?)
        output: stakeholders

      - step: 3_define_success
        action: invoke_tool
        tool: derive_success_metrics
        input:
          objective: ${problem_statement}
          target_market: ${stakeholders}
        output: success_metrics

      - step: 4_draft_content
        action: generate
        template: |
          |BRD-${next_id}|: "${feature_name}"
          ${problem_statement}

          **Business Objectives:**
          - ${primary_objective}
          - ${secondary_objective}

          **Stakeholders:**
          ${stakeholders}

          **Success Metrics:**
          ${success_metrics}
        output: draft_brd

      - step: 5_validate_technology_agnostic
        action: invoke_rule
        rule: BRD_R1_Technology_Agnostic
        input: ${draft_brd}
        output: validation_result

      - step: 6_revise_if_needed
        condition: validation_result.valid == False
        action: invoke_tool
        tool: abstract_to_business_value
        input: ${validation_result.violations}
        output: revised_brd

      - step: 7_confirm_with_user
        action: present
        content: ${draft_brd} or ${revised_brd}
        prompt: >
          Does this capture the business value? Any adjustments needed?

knowledge:
  - name: brd_exemplars
    type: examples
    source: inline
    entries:
      - tag: |BRD-1|
        content: >
          Develop a fully offline-capable, high-performance AI assistant framework.
          Enable responsive, privacy-preserving capabilities without cloud dependency.
        quality: excellent
        rationale: "Technology-agnostic, focuses on business value (privacy, offline)"

      - tag: |BRD-13| (BAD EXAMPLE)
        content: >
          Implement conversation history using SQLite database with semantic search.
        quality: poor
        violations:
          - "Specifies technology (SQLite)"
          - "Describes implementation (semantic search mechanism)"
        correction: >
          Enable contextual memory to reduce repetitive queries and increase
          productivity (target: 30% reduction in duplicate questions).

evaluations:
  - name: technology_leak_detection
    description: Ensure zero technology references in BRD content
    metric: violations_per_tag
    threshold: 0

    test_strategy: >
      For each BRD tag in documentation, scan for technology keywords.
      Any detection is a FAIL requiring immediate revision.

~~~

----------

### 27.3.3 Traceability_Auditor (Cross-Tier Validator)

**File:** `agents/traceability_auditor.yaml`

~~~yaml
name: Traceability_Auditor
version: "1.0.0"
description: >
  Cross-tier validation agent ensuring complete traceability chains from
  business requirements (BRD) through implementation stubs (ISP). Detects
  broken citations, orphaned tags, and circular dependencies.

personas:
  - name: Quality_Assurance_Engineer
    identity: >
      You are a meticulous QA engineer focused on documentation integrity.
      You think in terms of dependency graphs, citation chains, and validation
      rules. You catch errors humans miss—broken links, circular references,
      inconsistent inventories.

    expertise:
      - Graph theory (detecting cycles, orphans, unreachable nodes)
      - Citation syntax parsing (`← |PARENT|` extraction)
      - Reconciliation manifest validation
      - Automated testing and reporting

    communication_style: >
      Precise and systematic. Report findings with tag IDs, line numbers,
      and exact error descriptions. Provide actionable fix suggestions.

rules:
  - id: TRACE_R1_Complete_Chain
    description: Every ISP tag must trace back to BRD root
    enforcement: strict
    validation: |
      def validate_complete_chain(tag_id, documentation):
          """
          Traverse citations upward until BRD root or cycle detected.
          """
          visited = set()
          current = tag_id
          chain = [current]

          while not current.startswith("BRD"):
              if current in visited:
                  return {
                      "valid": False,
                      "error": "CIRCULAR_DEPENDENCY",
                      "cycle": chain
                  }

              visited.add(current)
              parents = extract_citations(documentation[current])

              if len(parents) == 0:
                  return {
                      "valid": False,
                      "error": "BROKEN_CHAIN",
                      "orphan": current,
                      "chain": chain
                  }

              # Follow first parent (arbitrary for validation)
              current = parents[0]
              chain.append(current)

          return {
              "valid": True,
              "chain": chain,
              "depth": len(chain)
          }

  - id: TRACE_R2_No_Forward_References
    description: Parent tags must exist before children cite them
    enforcement: strict
    validation: |
      def check_citation_exists(child_tag, parent_tag, documentation):
          if parent_tag not in documentation:
              return {
                  "valid": False,
                  "error": "MISSING_PARENT",
                  "child": child_tag,
                  "cited_parent": parent_tag,
                  "suggestion": f"Create {parent_tag} or correct citation"
              }
          return {"valid": True}

  - id: TRACE_R3_No_Sibling_Citations
    description: Prohibit peer tags from citing each other
    enforcement: strict
    validation: |
      def check_sibling_citation(tag_id, parent_tag):
          # Extract tier and block from both tags
          tag_match = re.match(r'([A-Z]{3})-(\d+)(\.(\d+))?', tag_id)
          parent_match = re.match(r'([A-Z]{3})-(\d+)(\.(\d+))?', parent_tag)

          if tag_match and parent_match:
              tag_tier, tag_block = tag_match.group(1), tag_match.group(2)
              parent_tier, parent_block = parent_match.group(1), parent_match.group(2)

              # Same tier and same block = siblings
              if tag_tier == parent_tier and tag_block == parent_block:
                  return {
                      "valid": False,
                      "error": "SIBLING_CITATION",
                      "child": tag_id,
                      "sibling": parent_tag,
                      "rule_violation": "Section 6.6 - Lateral Dependency Prohibition"
                  }

          return {"valid": True}

tools:
  - name: build_dependency_graph
    description: Construct complete citation graph from documentation
    output_schema:
      type: object
      properties:
	      nodes:
		      type: array
		      description: All tags in documentation
	      edges:
		      type: array
		      description: Citation relationships (child → parent)
	      statistics:
		      type: object
		      properties:
			      total_tags: integer
			      orphan_count: integer
			      max_depth: integer
			      avg_chain_length: float

    implementation: |
	  def build_graph(documentation):
	      graph = {
	          "nodes": list(documentation.keys()),
	          "edges": [],
	          "orphans": [],
	          "cycles": []
	      }

	      for tag_id, content in documentation.items():
	          parents = extract_citations(content)

	          if len(parents) == 0 and not tag_id.startswith("BRD"):
	              graph["orphans"].append(tag_id)

	          for parent in parents:
	              graph["edges"].append({
	                  "from": tag_id,
	                  "to": parent,
	                  "tier_transition": f"{get_tier(tag_id)} → {get_tier(parent)}"
	              })

	      # Detect cycles using DFS
	      graph["cycles"] = detect_cycles(graph["nodes"], graph["edges"])

	      # Calculate statistics
	      chains = [trace_to_root(tag, graph) for tag in graph["nodes"]]
	      graph["statistics"] = {
	          "total_tags": len(graph["nodes"]),
	          "orphan_count": len(graph["orphans"]),
	          "cycle_count": len(graph["cycles"]),
	          "max_depth": max(len(chain) for chain in chains),
	          "avg_chain_length": sum(len(chain) for chain in chains) / len(chains)
	      }

	      return graph

  - name: generate_traceability_report
    description: Comprehensive validation report with fix suggestions
    input_schema:
      type: object
      properties:
        documentation:
          type: object
          description: Complete DDR documentation
        focus_area:
          type: string
          enum: ["all", "tier", "tag", "manifest"]
          description: Scope of validation
      required: [documentation]
    output_schema:
      type: object
      properties:
        summary:
          type: object
          properties:
            status: {enum: ["PASS", "FAIL"]}
            total_errors: integer
            total_warnings: integer
            errors:
              type: array
            items:
              type: object
              properties:
                severity: {enum: ["ERROR", "WARNING", "INFO"]}
                category: string
                tag_id: string
                message: string
                fix_suggestion: string
                recommendations:
                  type: array
                  items: string

    implementation: |

      def generate_report(documentation, focus_area="all"):
        report = { "summary": {"status": "PASS", "total_errors": 0, "total_warnings": 0}, "errors": [], "recommendations": [] }

      # Build dependency graph
      graph = build_dependency_graph(documentation)

      # Check 1: Orphan detection
      for orphan in graph["orphans"]:
          report["errors"].append({
              "severity": "ERROR",
              "category": "MISSING_PARENT",
              "tag_id": orphan,
              "message": f"{orphan} has no parent citation (← |PARENT| missing)",
              "fix_suggestion": f"Add citation to appropriate parent tier or invoke orphan_resolution workflow"
          })
          report["summary"]["total_errors"] += 1

      # Check 2: Broken citations
      for edge in graph["edges"]:
          if edge["to"] not in graph["nodes"]:
              report["errors"].append({
                  "severity": "ERROR",
                  "category": "BROKEN_CITATION",
                  "tag_id": edge["from"],
                  "message": f"{edge['from']} cites non-existent parent {edge['to']}",
                  "fix_suggestion": f"Create {edge['to']} or correct citation in {edge['from']}"
              })
              report["summary"]["total_errors"] += 1

      # Check 3: Circular dependencies
      for cycle in graph["cycles"]:
          report["errors"].append({
              "severity": "ERROR",
              "category": "CIRCULAR_DEPENDENCY",
              "tag_id": cycle[0],
              "message": f"Circular citation chain detected: {' → '.join(cycle)}",
              "fix_suggestion": "Break cycle by removing one citation in the chain"
          })
          report["summary"]["total_errors"] += 1

      # Check 4: Sibling citations
      for edge in graph["edges"]:
          validation = check_sibling_citation(edge["from"], edge["to"])
          if not validation["valid"]:
              report["errors"].append({
                  "severity": "ERROR",
                  "category": "SIBLING_CITATION",
                  "tag_id": edge["from"],
                  "message": validation["error"],
                  "fix_suggestion": "Cite common parent tier instead of sibling"
              })
              report["summary"]["total_errors"] += 1

      # Check 5: Manifest accuracy
      for section in ["brd-root", "nfr-root", "fsd-root", "sad-root", "icd-root", "tdd-root", "isp-root"]:
          manifest = get_manifest(documentation, section)
          actual_tags = count_tags_in_section(documentation, section)

          if manifest["tag_count"] != actual_tags:
              report["errors"].append({
                  "severity": "WARNING",
                  "category": "MANIFEST_MISMATCH",
                  "tag_id": section,
                  "message": f"Manifest claims {manifest['tag_count']} tags, found {actual_tags}",
                  "fix_suggestion": "Invoke Manifest_Manager to synchronize"
              })
              report["summary"]["total_warnings"] += 1

      # Set overall status
      if report["summary"]["total_errors"] > 0:
          report["summary"]["status"] = "FAIL"

      # Generate recommendations
      if graph["statistics"]["max_depth"] > 10:
          report["recommendations"].append(
              "Deep citation chains detected (>10 levels). Consider refactoring for clarity."
          )

      if graph["statistics"]["orphan_count"] > 0:
          report["recommendations"].append(
              f"Resolve {graph['statistics']['orphan_count']} orphaned tags using upward/downward protocols (Report Section 5)."
          )

      return report

  - name: visualize_traceability
    description: Generate Mermaid diagram of citation relationships
    input_schema:
      type: object
      properties:
        root_tag:
          type: string
          description: Starting tag for visualization
        depth:
          type: integer
          default: 3
          description: How many levels to traverse
    output_schema:
      type: string
      description: Mermaid graph syntax

    implementation: |

      def generate_mermaid(root_tag, documentation, depth=3):
       visited = set()
       mermaid = ["graph TD"]

      def traverse(tag, current_depth):
          if current_depth > depth or tag in visited:
              return

          visited.add(tag)
          parents = extract_citations(documentation.get(tag, ""))

          for parent in parents:
              mermaid.append(f'    {tag}["{tag}"] --> {parent}["{parent}"]')
              traverse(parent, current_depth + 1)

      traverse(root_tag, 0)

      # Add styling
      mermaid.extend([
          "    classDef brd fill:#e1f5ff",
          "    classDef nfr fill:#fff3e0",
          "    classDef fsd fill:#f3e5f5",
          "    classDef sad fill:#e8f5e9",
          "    classDef icd fill:#fce4ec",
          "    classDef tdd fill:#fff9c4",
          "    classDef isp fill:#f1f8e9"
      ])

      # Apply styles
      for tag in visited:
          tier = get_tier(tag).lower()
          mermaid.append(f"    class {tag} {tier}")

      return "\n".join(mermaid)

workflows:
  - name: comprehensive_audit
    description: Full documentation integrity validation
    steps:
    - step: 1_build_graph
      action: invoke_tool
      tool: build_dependency_graph
      input: ${documentation}
      output: dependency_graph
    - step: 2_generate_report
      action: invoke_tool
      tool: generate_traceability_report
      input:
        documentation: ${documentation}
        focus_area: "all"
      output: validation_report
    - step: 3_check_manifests
      action: invoke_agent
      agent: Manifest_Manager
      task: validate_all
      input: ${documentation}
      output: manifest_status
    - step: 4_scan_anti_patterns
      action: invoke_agent
      agent: AntiPattern_Scanner
      task: scan_all
      input: ${documentation}
      output: anti_pattern_report
    - step: 5_compile_results
      action: aggregate
      inputs:
      - ${validation_report}
      - ${manifest_status}
      - ${anti_pattern_report}
      output: comprehensive_report
    - step: 6_present_findings
      action: present

    template: |
═══════════════════════════════════════════ DDR INTEGRITY AUDIT REPORT ═══════════════════════════════════════════

        Overall Status: ${comprehensive_report.status}

        STATISTICS:

        -   Total Tags: ${dependency_graph.statistics.total_tags}
        -   Max Chain Depth: ${dependency_graph.statistics.max_depth}
        -   Average Chain Length: ${dependency_graph.statistics.avg_chain_length}

        ERRORS: ${validation_report.summary.total_errors} ${format_errors(validation_report.errors)}

        WARNINGS: ${validation_report.summary.total_warnings} ${format_warnings(validation_report.errors)}

        MANIFEST STATUS: ${manifest_status.status} ${format_manifest_issues(manifest_status.issues)}

        ANTI-PATTERNS: ${anti_pattern_report.total_violations} ${format_anti_patterns(anti_pattern_report.violations)}

        RECOMMENDATIONS: ${format_recommendations(comprehensive_report.recommendations)}

        ═══════════════════════════════════════════

        Next Steps:

        1.  Fix all ERROR-level issues (blocking)
        2.  Address WARNING-level issues (recommended)
        3.  Apply recommendations for long-term maintainability
        4.  Re-run audit after fixes applied
-   name: trace_tag_to_root description: Show complete citation chain for specific tag

    steps:

    -   step: 1_validate_tag_exists action: check condition: ${tag_id} in ${documentation} on_failure: "ERROR: Tag ${tag_id} not found in documentation"

    -   step: 2_build_chain action: invoke_rule rule: TRACE_R1_Complete_Chain input: tag_id: ${tag_id} documentation: ${documentation} output: chain_result

    -   step: 3_visualize_chain action: invoke_tool tool: visualize_traceability input: root_tag: ${tag_id} documentation: ${documentation} depth: ${chain_result.depth} output: mermaid_diagram

    -   step: 4_present_chain action: present template: | Traceability Chain for ${tag_id}:

        ${format_chain_list(chain_result.chain)}

        Chain Depth: ${chain_result.depth} tiers

        Visualization:

        ```mermaid
        ${mermaid_diagram}

        ```

        Validation: ${chain_result.valid ? "✅ VALID" : "❌ BROKEN"}


knowledge:

-   name: validation_rules_reference type: reference source: file://DDR_Technical_Report.md#section-14 description: > Advanced traceability techniques including impact analysis queries, traceability graphs, and orphan detection algorithms.

evaluations:

-   name: orphan_detection_accuracy description: Verify orphan detection catches all uncited tags metric: recall threshold: 1.0

    test_cases:

    -   documentation: BRD-1: "Business requirement (root, no citation needed)" NFR-1: "Constraint ← |BRD-1|" FSD-1: "Feature spec (MISSING CITATION)" SAD-1: "Architecture ← |FSD-1|" expected_orphans: ["FSD-1"]

    -   documentation: BRD-1: "Root" NFR-1: "← |BRD-1|" FSD-1: "← |NFR-1|" FSD-2: "← |NFR-99|" # Parent doesn't exist expected_orphans: [] # FSD-2 has citation, but it's broken (different error) expected_broken: ["FSD-2"]

-   name: cycle_detection_accuracy description: Verify circular dependency detection metric: precision_and_recall threshold: 1.0

    test_cases:

    -   documentation: TAG-1: "← |TAG-2|" TAG-2: "← |TAG-3|" TAG-3: "← |TAG-1|" expected_cycle: ["TAG-1", "TAG-2", "TAG-3", "TAG-1"]

    -   documentation: BRD-1: "Root" NFR-1: "← |BRD-1|" FSD-1: "← |NFR-1|" expected_cycle: null


~~~

---

### 27.3.4 ISP_CodeGenerator (Implementation Stub Agent)

**File:** `agents/isp_codegenerator.yaml`

~~~yaml
name: ISP_CodeGenerator
version: "1.0.0"
description: >
  Specialized agent for generating Python implementation stubs (ISP tier).
  Creates executable scaffolding with Numpy-style docstrings, traceability
  markers, and implementation guidance based on TDD blueprints.

personas:
  - name: Senior_Developer
    identity: >
      You are a senior Python developer who writes clean, well-documented
      code stubs. You understand that stubs are NOT implementations—they
      provide structure and guidance for other developers. You excel at
      writing comprehensive docstrings that explain WHAT to implement and WHY.

    expertise:
      - Python 3.11+ idioms and type hints
      - Numpy-style docstring format
      - Class/method design patterns
      - Performance considerations for target hardware (AMD Ryzen 9, RTX 3080)
      - ONNX Runtime, ZeroMQ, PySide6 APIs

    communication_style: >
      Technical but pedagogical. Your docstrings teach developers how to
      implement the logic. You provide implementation notes, performance
      hints, and error handling guidance—but never complete implementations.

    constraints:
      - NEVER write complete function bodies (use `pass` statements)
      - ALWAYS include traceability markers (Ref: |TAG|)
      - ALWAYS provide implementation notes in docstrings
      - MUST use Numpy-style docstrings
      - MUST include type hints for all parameters and returns

rules:
  - id: ISP_R1_Stub_Only
    description: Function bodies must contain only `pass` statements
    enforcement: strict
    validation: |
      def validate_stub(code):
          """
          Check that function/method bodies are stubs, not implementations.
          """
          ast_tree = ast.parse(code)

          for node in ast.walk(ast_tree):
              if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                  # Function body should be single `pass` or docstring + pass
                  body = node.body

                  # Filter out docstrings
                  non_docstring_body = [
                      stmt for stmt in body
                      if not isinstance(stmt, ast.Expr) or
                         not isinstance(stmt.value, ast.Constant)
                  ]

                  # Check remaining statements
                  if len(non_docstring_body) > 1:
                      return {
                          "valid": False,
                          "error": f"Function {node.name} has implementation beyond stub",
                          "suggestion": "Replace implementation with `pass` and move logic to implementation notes"
                      }

                  if len(non_docstring_body) == 1:
                      if not isinstance(non_docstring_body[0], ast.Pass):
                          return {
                              "valid": False,
                              "error": f"Function {node.name} body must be `pass` statement",
                              "suggestion": "Use implementation notes in docstring instead"
                          }

          return {"valid": True}

  - id: ISP_R2_Traceability_Required
    description: All classes/functions must reference parent TDD tags
    enforcement: strict
    validation: |
      def check_traceability(code):
          """
          Verify docstrings contain 'Ref:' or 'Implements:' section with tags.
          """
          docstrings = extract_docstrings(code)
          missing_refs = []

          for entity, docstring in docstrings.items():
              if not ("Ref:" in docstring or "Implements:" in docstring or "References:" in docstring):
                  missing_refs.append(entity)

          if missing_refs:
              return {
                  "valid": False,
                  "error": "Missing traceability markers",
                  "entities": missing_refs,
                  "suggestion": "Add 'Implements' or 'References' section to docstrings"
              }

          return {"valid": True}

  - id: ISP_R3_Numpy_Docstring
    description: All docstrings must follow Numpy format
    enforcement: strict
    validation: |
      def validate_docstring_format(docstring):
          """
          Check for Numpy-style sections: Parameters, Returns, Raises, etc.
          """
          required_sections = {
              "function": ["Parameters", "Returns"],
              "class": ["Attributes"],
              "method": ["Parameters"]  # Returns optional for methods
          }

          # Parse docstring sections
          sections = parse_numpy_sections(docstring)

          # Validate based on entity type
          # (Implementation checks for section headers, formatting)

          return {"valid": True}  # Simplified for example

tools:
  - name: generate_class_stub
    description: Create Python class stub from TDD blueprint
    input_schema:
      type: object
      properties:
        tdd_tag:
          type: string
          description: TDD tag ID defining the component
        class_name:
          type: string
          description: Name of the class to generate
        parent_class:
          type: string
          description: Base class to inherit from (if any)
        dependencies:
          type: array
          items: string
          description: Required imports/dependencies
        methods:
          type: array
          items:
            type: object
            properties:
              name: string
              signature: string
              description: string
      required: [tdd_tag, class_name, methods]

    implementation: |
      def generate_class(tdd_tag, class_name, parent_class=None, dependencies=None, methods=None):
          code = []

          # Generate imports
          if dependencies:
              code.extend([f"import {dep}" for dep in dependencies])
              code.append("")

          # Generate class definition
          inheritance = f"({parent_class})" if parent_class else ""
          code.append(f"class {class_name}{inheritance}:")

          # Generate class docstring
          code.append('    """')
          code.append(f"    {get_description_from_tdd(tdd_tag)}")
          code.append('    ')
          code.append('    Implements')
          code.append('    ----------')
          code.append(f'    {tdd_tag}')
          code.append('    """')
          code.append('')

          # Generate __init__
          init_params = get_init_params_from_tdd(tdd_tag)
          code.append(f'    def __init__(self, {init_params}):')
          code.append('        """')
          code.append('        Initialize component.')
          code.append('        ')
          code.append('        Parameters')
          code.append('        ----------')
          # ... (generate parameter docs)
          code.append('        """')
          code.append('        pass')
          code.append('')

          # Generate methods
          for method in methods:
              code.extend(generate_method_stub(method, tdd_tag))

          return "\n".join(code)

  - name: generate_method_stub
    description: Create method stub with comprehensive docstring
    input_schema:
      type: object
      properties:
        method_name: string
        signature: string
        returns: string
        description: string
        parent_tag: string
      required: [method_name, signature, parent_tag]

    output_schema:
      type: string
      description: Python method stub with Numpy docstring

    template: |
      def ${method_name}(${signature}):
          """
          ${description}

          Parameters
          ----------
          ${generate_param_docs(signature)}

          Returns
          -------
          ${returns}
              ${return_description}

          Implementation Notes
          --------------------
          ${get_implementation_notes_from_tdd(parent_tag)}

          Performance
          -----------
          ${get_performance_requirements(parent_tag)}

          References
          ----------
          ${parent_tag}
          """
          pass

  - name: add_implementation_hints
    description: Generate detailed implementation guidance from TDD/ICD
    input_schema:
      type: object
      properties:
        tdd_tag: string
        icd_tags:
          type: array
          items: string
        sad_tags:
          type: array
          items: string
      required: [tdd_tag]

    output_schema:
      type: array
      items:
        type: string
        description: Implementation step

    implementation: |
      def generate_hints(tdd_tag, icd_tags=None, sad_tags=None):
          hints = []

          # Extract requirements from TDD
          tdd_content = get_tag_content(tdd_tag)
          responsibilities = extract_responsibilities(tdd_content)

          for responsibility in responsibilities:
              hints.append(f"# Step: {responsibility}")

              # Add data schema references if relevant
              if icd_tags:
                  for icd_tag in icd_tags:
                      if is_related(responsibility, icd_tag):
                          schema = get_schema_from_icd(icd_tag)
                          hints.append(f"# Use schema from {icd_tag}: {schema}")

              # Add architectural pattern hints
              if sad_tags:
                  for sad_tag in sad_tags:
                      if is_related(responsibility, sad_tag):
                          pattern = get_pattern_from_sad(sad_tag)
                          hints.append(f"# Apply pattern from {sad_tag}: {pattern}")

          return hints

workflows:
  - name: create_isp_from_tdd
    description: Generate complete ISP stub from TDD blueprint

    steps:
      - step: 1_validate_tdd_exists
        action: check
        condition: ${tdd_tag} in ${documentation}
        on_failure: "ERROR: TDD tag ${tdd_tag} not found"

      - step: 2_extract_tdd_metadata
        action: parse
        input: ${get_tag_content(tdd_tag)}
        output:
          - class_name
          - dependencies
          - methods
          - internal_structures

      - step: 3_gather_related_tags
        action: query
        queries:
          - "Find ICD tags cited by ${tdd_tag}"
          - "Find SAD tags cited by ${tdd_tag}"
        output:
          - icd_tags
          - sad_tags

      - step: 4_generate_class_stub
        action: invoke_tool
        tool: generate_class_stub
        input:
          tdd_tag: ${tdd_tag}
          class_name: ${class_name}
          dependencies: ${dependencies}
          methods: ${methods}
        output: class_code

      - step: 5_add_implementation_notes
        action: invoke_tool
        tool: add_implementation_hints
        input:
          tdd_tag: ${tdd_tag}
          icd_tags: ${icd_tags}
          sad_tags: ${sad_tags}
        output: implementation_hints

      - step: 6_inject_hints_into_docstrings
        action: enhance
        input:
          code: ${class_code}
          hints: ${implementation_hints}
        output: enhanced_code

      - step: 7_validate_stub
        action: invoke_rule
        rule: ISP_R1_Stub_Only
        input: ${enhanced_code}
        output: validation_result

      - step: 8_validate_traceability
        action: invoke_rule
        rule: ISP_R2_Traceability_Required
        input: ${enhanced_code}
        output: trace_validation

      - step: 9_format_code
        action: format
        formatter: black
        line_length: 88
        input: ${enhanced_code}
        output: formatted_code

      - step: 10_present_stub
        action: present
        content: ${formatted_code}
        prompt: >
          Generated implementation stub for ${tdd_tag}.

          Next steps:
          1. Review docstrings for accuracy
          2. Implement logic (replace `pass` statements)
          3. Run type checker: mypy ${filename}
          4. Run tests

knowledge:
  - name: python_patterns
    type: reference
    source: file://python_patterns.yaml
    description: Common design patterns optimized for MAGGIE architecture

    patterns:
      - name: ServiceClient_Pattern
        description: Standard pattern for process communication services
        template: |
          class ${ClassName}(ServiceClient):
              def __init__(self, config_path: str):
                  super().__init__("${service_name}", config_path)
                  # Service-specific initialization
                  pass

      - name: PriorityQueue_Consumer
        description: Non-blocking queue processing loop
        template: |
          def process_queue(self, timeout: float = 0.1) -> None:
              while self.running:
                  try:
                      priority, counter, message = self.queue.get(timeout=timeout)
                      self.handle_message(message)
                  except queue.Empty:
                      # No message available, continue
                      pass

      - name: ZMQ_Receiver_Thread
        description: Dedicated thread for socket polling
        template: |
          def _start_receiver_thread(self) -> threading.Thread:
              def receiver_loop():
                  poller = zmq.Poller()
                  poller.register(self.socket, zmq.POLLIN)

                  while self.running:
                      socks = dict(poller.poll(timeout=self.poll_timeout_ms))
                      if self.socket in socks:
                          frames = self.socket.recv_multipart()
                          self.queue.put((priority, next(self.counter), frames))

              thread = threading.Thread(target=receiver_loop, daemon=True)
              thread.start()
              return thread

  - name: hardware_optimization_hints
    type: reference
    source: inline
    description: Performance optimization guidance for target hardware

    hints:
      - context: "ONNX inference on RTX 3080"
        suggestion: >
          Use ort.SessionOptions with graph_optimization_level=ort.GraphOptimizationLevel.ORT_ENABLE_ALL
          and execution_mode=ort.ExecutionMode.ORT_PARALLEL for maximum throughput.

      - context: "CPU-bound audio processing on AMD Ryzen 9 5900X"
        suggestion: >
          Utilize numpy vectorization and avoid Python loops. Consider numba JIT
          compilation for hot paths. Target 12 threads for parallel processing.

      - context: "Memory management with 32GB RAM"
        suggestion: >
          Monitor RSS with psutil. Implement lazy loading for large models.
          Use memory-mapped files for datasets >1GB.

evaluations:
  - name: stub_purity
    description: Ensure generated stubs contain no implementation logic
    metric: violations_per_stub
    threshold: 0

    test_strategy: >
      Parse generated code with AST. For each function/method, verify body
      contains only `pass` statement (optionally preceded by docstring).
      Any other statements are violations.

  - name: docstring_completeness
    description: Verify all required Numpy sections present
    metric: completeness_percentage
    threshold: 1.0

    required_sections:
      functions:
        - Parameters
        - Returns
        - References
      classes:
        - Attributes
        - Implements
      methods:
        - Parameters
        - Implementation Notes
        - References

~~~

----------

## 27.4 Custom Tool Definitions

### 27.4.1 Tag Management Tools

**File:** `tools/tag_operations.yaml`

~~~yaml
name: tag_operations
version: "1.0.0"
description: Core tools for creating, updating, and managing DDR tags

tools:
  - name: create_tag
    description: Generate new tag with proper ID and traceability
    input_schema:
      type: object
      properties:
        tier:
          type: string
          enum: ["BRD", "NFR", "FSD", "SAD", "ICD", "TDD", "ISP"]
        content: string
        parent_tags:
          type: array
          items: string
        block_id:
          type: integer
          description: Optional: specific block number (auto-assigned if omitted)
      required: [tier, content, parent_tags]

    output_schema:
      type: object
      properties:
        tag_id: string
        formatted_content: string
        citations: array

    implementation: |
      def create_tag(tier, content, parent_tags, block_id=None):
          # Determine next available ID
          if block_id is None:
              block_id = get_next_block_id(tier)

          tag_id = f"{tier}-{block_id}"

          # Format content with citations
          citations_text = ", ".join([f"|{parent}|" for parent in parent_tags])
          formatted = f"{tag_id} ← {citations_text}: \"{content}\""

          # Validate against tier rules
          validation = validate_tier_compliance(tier, content)
          if not validation["valid"]:
              raise ValueError(f"Tier violation: {validation['error']}")

          return {
              "tag_id": tag_id,
              "formatted_content": formatted,
              "citations": parent_tags
          }

  - name: update_tag
    description: Modify existing tag content with change tracking
    input_schema:
      type: object
      properties:
        tag_id: string
        new_content: string
        change_reason: string
      required: [tag_id, new_content]

    output_schema:
      type: object
      properties:
        tag_id: string
        old_content: string
        new_content: string
        affected_children:
array reconciliation_required: boolean

```
implementation: |
  def update_tag(tag_id, new_content, change_reason=None):
      # Retrieve existing content
      old_content = get_tag_content(tag_id)

      # Find all children that cite this tag
      affected_children = find_tags_citing(tag_id)

      # Semantic diff analysis
      changes = analyze_semantic_changes(old_content, new_content)

      # Determine if downstream reconciliation needed
      reconciliation_required = (
          changes["constraints_added"] or
          changes["constraints_removed"] or
          len(affected_children) > 0
      )

      # Update content
      set_tag_content(tag_id, new_content)

      # Mark manifests as dirty if reconciliation needed
      if reconciliation_required:
          section = get_section_for_tag(tag_id)
          set_manifest_dirty(section, tag_id, affected_children)

      # Log change
      log_tag_modification(tag_id, old_content, new_content, change_reason)

      return {
          "tag_id": tag_id,
          "old_content": old_content,
          "new_content": new_content,
          "affected_children": affected_children,
          "reconciliation_required": reconciliation_required,
          "semantic_changes": changes
      }

```

-   name: deprecate_tag description: Mark tag as deprecated without deletion input_schema: type: object properties: tag_id: string replacement_tag: type: string description: Optional: ID of replacement tag deprecation_reason: string version: string required: [tag_id, version]

    implementation: | def deprecate_tag(tag_id, replacement_tag=None, deprecation_reason=None, version=None): content = get_tag_content(tag_id)

    ```
      # Add deprecation marker
      replacement_text = f" → See |{replacement_tag}|" if replacement_tag else ""
      deprecated_content = f"{tag_id} [DEPRECATED v{version}{replacement_text}]: {content}"

      if deprecation_reason:
          deprecated_content += f"\n\n**Deprecation Reason:** {deprecation_reason}"

      # Update tag
      set_tag_content(tag_id, deprecated_content)

      # Find all children and flag for review
      children = find_tags_citing(tag_id)
      for child in children:
          add_review_note(child, f"Parent {tag_id} deprecated, verify citation validity")

      return {
          "deprecated_tag": tag_id,
          "replacement": replacement_tag,
          "affected_children": children
      }

    ```

-   name: extract_citations description: Parse parent citations from tag content input_schema: type: object properties: content: string required: [content]

    output_schema: type: array items: string description: List of cited parent tag IDs

    implementation: | import re

    def extract_citations(content): # Pattern: ← |TAG-ID| or ← |TAG-1|, |TAG-2| pattern = r'←\s*|([A-Z]{3}-\d+(?:.\d+)?)|' matches = re.findall(pattern, content) return matches

-   name: find_tags_citing description: Find all tags that cite a given parent tag input_schema: type: object properties: parent_tag: string required: [parent_tag]

    output_schema: type: array items: type: object properties: tag_id: string tier: string content_preview: string

    implementation: | def find_tags_citing(parent_tag): results = []

    ```
      for tag_id, content in get_all_tags():
          citations = extract_citations(content)
          if parent_tag in citations:
              results.append({
                  "tag_id": tag_id,
                  "tier": get_tier(tag_id),
                  "content_preview": content[:100] + "..."
              })

      return results

    ```


~~~

---

### 27.4.2 Validation Tools

**File:** `tools/validation.yaml`

~~~yaml
name: validation_tools
version: "1.0.0"
description: Automated validation and integrity checking tools

tools:
  - name: validate_tier_compliance
    description: Check if content complies with tier-specific rules
    input_schema:
      type: object
      properties:
        tier: string
        content: string
      required: [tier, content]

    output_schema:
      type: object
      properties:
        valid: boolean
        violations: array
        suggestions: array

    implementation: |
      def validate_tier_compliance(tier, content):
          violations = []
          suggestions = []

          # Tier-specific validation rules
          tier_rules = {
              "BRD": {
                  "forbidden_terms": ["ZeroMQ", "ONNX", "PostgreSQL", "API", "socket", "thread", "class", "GPU", "CPU core"],
                  "required_elements": ["business value", "stakeholder", "metric"],
                  "message": "BRD must be technology-agnostic and business-focused"
              },
              "NFR": {
                  "required_elements": ["metric", "constraint", "limit"],
                  "must_contain_numbers": True,
                  "message": "NFR must specify measurable constraints"
              },
              "FSD": {
                  "forbidden_terms": ["zmq.ROUTER", "onnxruntime", "PySide6", "class ", "def "],
                  "message": "FSD must describe behavior, not implementation"
              },
              "ICD": {
                  "required_elements": ["schema", "format", "contract"],
                  "message": "ICD must define data structures"
              },
              "TDD": {
                  "required_elements": ["class", "method", "component"],
                  "forbidden_elements": ["implementation", "algorithm"],
                  "message": "TDD defines structure, not logic"
              },
              "ISP": {
                  "required_elements": ["def ", "pass"],
                  "must_be_code": True,
                  "message": "ISP must be executable Python stubs"
              }
          }

          rules = tier_rules.get(tier, {})

          # Check forbidden terms
          for term in rules.get("forbidden_terms", []):
              if term.lower() in content.lower():
                  violations.append(f"Forbidden term in {tier}: '{term}'")
                  suggestions.append(f"Abstract '{term}' to {tier}-appropriate language")

          # Check required elements
          for element in rules.get("required_elements", []):
              if element.lower() not in content.lower():
                  violations.append(f"Missing required element in {tier}: '{element}'")

          # Special checks
          if rules.get("must_contain_numbers") and not re.search(r'\d+', content):
              violations.append(f"{tier} must contain numeric constraints")
              suggestions.append("Add measurable targets (e.g., <1s latency, 99.9% uptime)")

          return {
              "valid": len(violations) == 0,
              "violations": violations,
              "suggestions": suggestions,
              "tier": tier
          }

  - name: check_manifest_integrity
    description: Verify reconciliation manifest accuracy
    input_schema:
      type: object
      properties:
        section_id: string
        documentation: object
      required: [section_id, documentation]

    output_schema:
      type: object
      properties:
        accurate: boolean
        manifest_count: integer
        actual_count: integer
        missing_tags: array
        extra_tags: array

    implementation: |
      def check_manifest_integrity(section_id, documentation):
          # Get manifest for section
          manifest = get_reconciliation_manifest(documentation, section_id)

          # Count actual tags in section
          section_prefix = section_id.replace("-root", "").upper()
          actual_tags = [
              tag for tag in documentation.keys()
              if tag.startswith(section_prefix)
          ]

          # Compare with manifest inventory
          manifest_tags = set(manifest.get("tag_inventory", []))
          actual_tag_set = set(actual_tags)

          missing_tags = list(actual_tag_set - manifest_tags)
          extra_tags = list(manifest_tags - actual_tag_set)

          manifest_count = manifest.get("tag_count", 0)
          actual_count = len(actual_tags)

          return {
              "accurate": (manifest_count == actual_count and
                          len(missing_tags) == 0 and
                          len(extra_tags) == 0),
              "manifest_count": manifest_count,
              "actual_count": actual_count,
              "missing_tags": missing_tags,
              "extra_tags": extra_tags,
              "section": section_id
          }

  - name: detect_anti_patterns
    description: Scan for common documentation anti-patterns
    input_schema:
      type: object
      properties:
        documentation: object
        pattern_set:
          type: string
          enum: ["all", "critical", "recommended"]
          default: "all"
      required: [documentation]

    output_schema:
      type: object
      properties:
        total_violations: integer
        by_severity:
          type: object
          properties:
            error: integer
            warning: integer
            info: integer
        violations: array

    implementation: |
      def detect_anti_patterns(documentation, pattern_set="all"):
          anti_patterns = [
              {
                  "name": "technology_in_brd",
                  "severity": "error",
                  "regex": r'\|BRD-\d+\|.*(?:ZeroMQ|ONNX|PostgreSQL|React|Docker|GPU|CPU)',
                  "message": "Technology reference in BRD tier (must be abstract)",
                  "fix": "Move technology choice to SAD tier, keep BRD business-focused"
              },
              {
                  "name": "implementation_in_fsd",
                  "severity": "error",
                  "regex": r'\|FSD-\d+\|.*(?:class |def |import |socket\.|thread\.)',
                  "message": "Implementation details in FSD tier (behavior only)",
                  "fix": "Move implementation to TDD/ISP tiers"
              },
              {
                  "name": "schema_in_sad",
                  "severity": "warning",
                  "regex": r'\|SAD-\d+\|.*\{["\'][\w_]+["\']:\s*["\']',
                  "message": "JSON/YAML schema in SAD tier (belongs in ICD)",
                  "fix": "Move data schemas to ICD tier"
              },
              {
                  "name": "sibling_citation",
                  "severity": "error",
                  "regex": r'\|([A-Z]{3})-(\d+)\.(\d+)\|.*←.*\|\1-\2\.\d+\|',
                  "message": "Sibling citation detected (prohibited)",
                  "fix": "Cite common parent tier instead of peer tag"
              },
              {
                  "name": "missing_rationale",
                  "severity": "warning",
                  "regex": r'\|SAD-\d+\|.*(?:Pattern|Technology|Choice).*',
                  "negative_lookahead": r'Rationale|RATIONALE|Why',
                  "message": "Design decision without rationale",
                  "fix": "Add rationale section explaining why this choice was made"
              },
              {
                  "name": "vague_nfr",
                  "severity": "warning",
                  "regex": r'\|NFR-\d+\|.*(?:fast|slow|small|large|good|bad)(?!\s+\d)',
                  "message": "Vague constraint in NFR (must be quantifiable)",
                  "fix": "Replace qualitative terms with numeric targets (e.g., <1s, <100MB)"
              }
          ]

          violations = []
          severity_counts = {"error": 0, "warning": 0, "info": 0}

          for tag_id, content in documentation.items():
              for pattern in anti_patterns:
                  # Apply pattern filtering
                  if pattern_set == "critical" and pattern["severity"] != "error":
                      continue

                  # Check regex
                  if re.search(pattern["regex"], content):
                      # Check negative lookahead if specified
                      if "negative_lookahead" in pattern:
                          if re.search(pattern["negative_lookahead"], content):
                              continue  # Pattern matched, skip

                      violations.append({
                          "tag_id": tag_id,
                          "pattern": pattern["name"],
                          "severity": pattern["severity"],
                          "message": pattern["message"],
                          "fix": pattern["fix"]
                      })
                      severity_counts[pattern["severity"]] += 1

          return {
              "total_violations": len(violations),
              "by_severity": severity_counts,
              "violations": violations
          }

~~~

----------

## 27.5 Workflow Definitions

### 27.5.1 Complete Feature Documentation Workflow

**File:** `workflows/feature_documentation.yaml`

~~~yaml
name: complete_feature_documentation
version: "1.0.0"
description: End-to-end workflow for documenting new feature from BRD through ISP

trigger:
  type: user_command
  command: "document feature"
  parameters:
    - feature_name: string
    - feature_description: string (optional)

agents:
  coordinator: DDR_Orchestrator
  specialists:
    - BRD_Strategist
    - NFR_Enforcer
    - FSD_Analyst
    - SAD_Architect
    - ICD_DataEngineer
    - TDD_Designer
    - ISP_CodeGenerator
  validators:
    - Traceability_Auditor
    - Manifest_Manager

stages:
  - stage: 1_business_requirements
    name: "Define Business Case"
    agent: BRD_Strategist

    tasks:
      - task: gather_business_context
        prompt: |
          Let's document the feature: ${feature_name}

          I need to understand the business value first. Please help me answer:

          1. **Problem Statement:** What user pain point or market opportunity
             does this feature address?

          2. **Stakeholders:** Who benefits from this feature?
             - End users (how?)
             - Business owners (revenue impact? competitive advantage?)
             - Other stakeholders (compliance, developers, partners?)

          3. **Success Metrics:** How will we measure success?
             - User adoption targets?
             - Performance goals?
             - Business outcomes (retention, engagement, revenue)?

        input_method: interactive_interview
        output: business_context

      - task: create_brd_tags
        agent: BRD_Strategist
        workflow: create_brd_tag
        input: ${business_context}
        output: brd_tags

      - task: validate_brd
        tool: validate_tier_compliance
        input:
          tier: "BRD"
          content: ${brd_tags}
        validation: assert result.valid == true

  - stage: 2_constraints_definition
    name: "Establish Constraints & Limits"
    agent: NFR_Enforcer
    depends_on: [stage_1]

    tasks:
      - task: derive_constraints
        prompt: |
          Based on the business requirement for ${feature_name}, let's define
          the technical constraints:

          1. **Performance Targets:**
             - Latency requirements? (e.g., <1s response time)
             - Throughput needs? (e.g., 1000 requests/second)

          2. **Resource Limits:**
             - CPU/GPU constraints? (remember: RTX 3080 10GB VRAM, Ryzen 9 5900X)
             - Memory footprint? (32GB total RAM available)
             - Storage? (model sizes, data retention)

          3. **Security/Privacy:**
             - Data protection requirements?
             - Compliance needs? (GDPR, HIPAA, etc.)

          4. **Scalability:**
             - Max users/devices/requests?
             - Growth projections?

        input_method: interactive_interview
        output: constraints

      - task: create_nfr_tags
        agent: NFR_Enforcer
        input:
          business_requirements: ${brd_tags}
          constraints: ${constraints}
        output: nfr_tags

  - stage: 3_feature_specification
    name: "Define User-Facing Behavior"
    agent: FSD_Analyst
    depends_on: [stage_2]

    tasks:
      - task: design_user_workflows
        prompt: |
          Now let's specify what users will experience with ${feature_name}:

          1. **User Actions:** What can users do?
             - Voice commands?
             - GUI interactions?
             - Configuration settings?

          2. **System Responses:** How does the system respond?
             - Visual feedback?
             - Audio responses?
             - State changes?

          3. **Error Scenarios:** What happens when things go wrong?
             - Fallback behaviors?
             - Error messages?
             - Recovery actions?

          4. **Workflows:** Walk me through the complete user journey.

        input_method: interactive_interview
        output: workflows

      - task: create_fsd_tags
        agent: FSD_Analyst
        input:
          workflows: ${workflows}
          parent_nfr: ${nfr_tags}
        output: fsd_tags

  - stage: 4_architecture_design
    name: "Design System Architecture"
    agent: SAD_Architect
    depends_on: [stage_3]

    tasks:
      - task: select_patterns
        prompt: |
          For ${feature_name}, I need to design the architecture:

          1. **Component Allocation:** Which process handles what?
             - Core Process?
             - UI Process?
             - Runtime Process (GPU)?
             - Audio Process (CPU)?
             - New service needed?

          2. **Integration Pattern:** How do components communicate?
             - Request-Response (ROUTER-DEALER)?
             - Fire-and-Forget (PUSH-PULL)?
             - Event broadcast?

          3. **Technology Choices:** What libraries/frameworks?
             (Must cite NFR constraints as justification)

          4. **Design Principles:** Any special considerations?
             - Concurrency model?
             - Data flow?
             - Fault tolerance?

        input_method: interactive_interview
        output: architecture_decisions

      - task: create_sad_tags
        agent: SAD_Architect
        input:
          fsd_requirements: ${fsd_tags}
          nfr_constraints: ${nfr_tags}
          decisions: ${architecture_decisions}
        output: sad_tags

      - task: generate_topology_diagram
        tool: generate_mermaid_diagram
        input:
          type: "component_topology"
          components: ${extract_components(sad_tags)}
        output: topology_diagram

  - stage: 5_interface_contracts
    name: "Define Data Contracts"
    agent: ICD_DataEngineer
    depends_on: [stage_4]

    tasks:
      - task: identify_data_flows
        action: analyze
        input: ${sad_tags}
        logic: |
          Extract all data exchanges between components:
          - IPC messages (commands, responses)
          - Configuration schemas
          - Database schemas
          - File formats
        output: data_flows

      - task: create_icd_tags
        agent: ICD_DataEngineer
        input:
          data_flows: ${data_flows}
          sad_architecture: ${sad_tags}
        output: icd_tags

      - task: validate_schemas
        tool: validate_json_yaml_schemas
        input: ${icd_tags}
        validation: assert all_schemas_valid

  - stage: 6_component_design
    name: "Blueprint Components"
    agent: TDD_Designer
    depends_on: [stage_5]

    tasks:
      - task: identify_components
        action: analyze
        input: ${sad_tags}
        logic: |
          Extract component definitions:
          - Classes needed
          - Methods required
          - Dependencies
          - Internal data structures
        output: components

      - task: create_tdd_tags
        agent: TDD_Designer
        input:
          components: ${components}
          icd_schemas: ${icd_tags}
          sad_architecture: ${sad_tags}
        output: tdd_tags

  - stage: 7_implementation_stubs
    name: "Generate Code Stubs"
    agent: ISP_CodeGenerator
    depends_on: [stage_6]

    tasks:
      - task: generate_stubs
        agent: ISP_CodeGenerator
        workflow: create_isp_from_tdd
        input:
          tdd_blueprints: ${tdd_tags}
          icd_schemas: ${icd_tags}
        output: isp_tags

      - task: validate_stubs
        rules:
          - ISP_R1_Stub_Only
          - ISP_R2_Traceability_Required
          - ISP_R3_Numpy_Docstring
        input: ${isp_tags}
        validation: assert all_rules_pass

  - stage: 8_validation
    name: "Validate Complete Chain"
    agent: Traceability_Auditor
    depends_on: [stage_7]

    tasks:
      - task: audit_traceability
        workflow: comprehensive_audit
        input:
          all_tags: ${collect_all_tags()}
        output: audit_report

      - task: check_for_errors
        condition: audit_report.summary.total_errors > 0
        action: halt_with_message
        message: |
          ❌ Traceability validation FAILED

          ${audit_report.summary.total_errors} errors detected:
          ${format_errors(audit_report.errors)}

          Please fix these issues before proceeding.

  - stage: 9_manifest_update
    name: "Update Reconciliation Manifests"
    agent: Manifest_Manager
    depends_on: [stage_8]

    tasks:
      - task: synchronize_manifests
        action: update_all_manifests
        input:
          new_tags:
            brd: ${brd_tags}
            nfr: ${nfr_tags}
            fsd: ${fsd_tags}
            sad: ${sad_tags}
            icd: ${icd_tags}
            tdd: ${tdd_tags}
            isp: ${isp_tags}
        output: updated_manifests

      - task: verify_manifest_accuracy
        tool: check_manifest_integrity
        for_each: ${get_all_sections()}
        validation: assert all_accurate

completion:
  summary_template: |
    ═══════════════════════════════════════════════════════════
    ✅ Feature Documentation Complete: ${feature_name}
    ═══════════════════════════════════════════════════════════

    **Created Tags:**
    - BRD (Business): ${count(brd_tags)} tags
    - NFR (Constraints): ${count(nfr_tags)} tags
    - FSD (Behavior): ${count(fsd_tags)} tags
    - SAD (Architecture): ${count(sad_tags)} tags
    - ICD (Contracts): ${count(icd_tags)} tags
    - TDD (Design): ${count(tdd_tags)} tags
    - ISP (Stubs): ${count(isp_tags)} tags

    **Total:** ${count_all_tags()} new tags added

    **Traceability:** ✅ All chains validated
    **Manifests:** ✅ All synchronized
    **Anti-patterns:** ${audit_report.anti_pattern_count} (review recommended)

    **Architecture Diagram:**
    ```mermaid
    ${topology_diagram}
    ```

    **Next Steps:**
    1. Review generated implementation stubs in ISP tier
    2. Implement logic (replace `pass` statements with actual code)
    3. Run type checker: `mypy src/`
    4. Write unit tests for each component
    5. Run integration tests

    **Documentation Location:**
    - Main DDR: `docs/DDR.rst`
    - Code stubs: `src/${feature_module}/`

    ═══════════════════════════════════════════════════════════

  artifacts:
    - type: documentation
      path: "docs/DDR.rst"
      sections: ${list_all_modified_sections()}

    - type: code_stubs
      path: "src/${feature_module}/"
      files: ${list_generated_stubs()}

    - type: diagrams
      path: "docs/diagrams/${feature_name}/"
      files:
        - topology.mmd
        - traceability.mmd

    - type: validation_report
      path: "logs/validation/${timestamp}.json"
      content: ${audit_report}

~~~

----------

## 27.6 Evaluation Definitions

**File:** `evaluations/ddr_quality_metrics.yaml`

~~~yaml
name: ddr_quality_metrics
version: "1.0.0"
description: Comprehensive quality evaluation suite for DDR documentation

evaluations:
  - name: classification_accuracy
    description: Measure tier classification accuracy against ground truth
    type: accuracy_test
    dataset: test_cases/tier_classification.json
    threshold: 0.95

    metric: percentage_correct

    test_execution:
      for_each_case:
        - invoke: DDR_Orchestrator.classify_information
          input: ${test_case.content}
          expected: ${test_case.expected_tier}
          scoring: exact_match

    reporting:
      - confusion_matrix: true
      - per_tier_accuracy: true
      - failure_analysis: true

  - name: traceability_completeness
    description: Verify citation completeness and validity
    type: graph_validation
    threshold: 1.0

    metrics:
      - citation_coverage: "% of non-root tags with valid parent citations"
      - broken_link_rate: "% of citations pointing to non-existent tags"
      - orphan_rate: "% of tags without any parent"
      - cycle_count: "Number of circular dependencies detected"

    test_execution:
      - build_dependency_graph: true
      - validate_all_citations: true
      - detect_orphans: true
      - detect_cycles: true

    pass_criteria:
      - citation_coverage >= 1.0
      - broken_link_rate == 0.0
      - orphan_rate == 0.0
      - cycle_count == 0

  - name: anti_pattern_detection_rate
    description: Identify common documentation mistakes
    type: pattern_matching
    threshold_violations: 0

    patterns_tested:
      - technology_in_brd
      - implementation_in_fsd
      - schema_in_sad
      - sibling_citations
      - missing_rationale
      - vague_constraints

    test_execution:
      invoke: detect_anti_patterns
      input: ${full_documentation}
      pattern_set: "all"

    scoring:
      - error_severity: fail_immediately
      - warning_severity: log_and_continue
      - info_severity: informational_only

  - name: manifest_accuracy
    description: Verify reconciliation manifest synchronization
    type: inventory_check
    threshold: 1.0

    test_execution:
      for_each_section: [brd-root, nfr-root, fsd-root, sad-root, icd-root, tdd-root, isp-root]
        - invoke: check_manifest_integrity
          expected: accurate == true

    reporting:
      - discrepancies_by_section: true
      - missing_tags_list: true
      - extra_tags_list: true

  - name: stub_purity
    description: Ensure ISP stubs contain no implementation logic
    type: code_analysis
    threshold: 1.0

    test_execution:
      for_each_isp_tag:
        - parse_with_ast: true
        - check_function_bodies:
            allowed_statements: ["pass", "docstring"]
            forbidden: ["return", "if", "for", "while", "try"]

    pass_criteria:
      - all_functions_are_stubs: true
      - no_implementation_logic: true

  - name: docstring_completeness
    description: Verify Numpy-style docstring compliance
    type: documentation_analysis
    threshold: 0.95

    required_sections:
      classes:
        - "Attributes"
        - "Implements" or "References"
      functions:
        - "Parameters"
        - "Returns"
        - "References"
      methods:
        - "Parameters"
        - "Implementation Notes" (for stubs)
        - "References"

    test_execution:
      for_each_code_entity:
        - extract_docstring: true
        - parse_numpy_sections: true
        - check_required_sections: true

    scoring:
      - completeness_percentage: count_valid / count_total

  - name: end_to_end_workflow_success
    description: Test complete feature documentation workflow
    type: integration_test

    test_scenario:
      feature_name: "Test Feature XYZ"
      feature_description: "A test feature for workflow validation"

    test_execution:
      - invoke_workflow: complete_feature_documentation
        input: ${test_scenario}
        expected_stages_completed: 9
        expected_artifacts:
          - brd_tags: ">= 1"
          - nfr_tags: ">= 1"
          - fsd_tags: ">= 1"
          - sad_tags: ">= 1"
          - icd_tags: ">= 1"
          - tdd_tags: ">= 1"
          - isp_tags: ">= 1"

    validation:
      - all_stages_passed: true
      - traceability_chain_valid: true
      - manifests_synchronized: true
      - no_anti_patterns: true
      - code_stubs_valid: true

continuous_evaluation:
  schedule: "on_commit"

  quick_checks:
    - classification_accuracy
    - traceability_completeness
    - anti_pattern_detection_rate

  full_suite:
    schedule: "daily"
    include_all: true

  reporting:
    format: json
    destination: "logs/evaluations/"
    notification:
      on_failure: true
      channels: ["console", "log_file"]

~~~

----------

## 27.7 Integration with Antigravity IDE

### 27.7.1 Project Configuration

**File:** `.antigravity/project.yaml`

~~~yaml
project:
  name: "MAGGIE Documentation System"
  version: "5.0"
  type: "documentation_framework"

  description: >
    AI-assisted Development Documentation Roadmap (DDR) for the MAGGIE
    localized Python AI assistant framework. Implements seven-tier
    hierarchical documentation with automated validation and traceability.

agents:
  load_from:
    - "agents/*.yaml"

  default_agent: DDR_Orchestrator

  agent_discovery:
    auto_load: true
    scan_directories:
      - "agents/"
      - "tools/" - "workflows/"

tools: load_from: - "tools/*.yaml"

global_tools: - tag_operations - validation_tools - manifest_management

workflows: load_from: - "workflows/*.yaml"

featured_workflows: - complete_feature_documentation - orphan_resolution - refactoring_migration - comprehensive_audit

knowledge_bases:

-   name: ddr_specification type: reference_documentation sources:

    -   file: "docs/ddr_meta_standard.txt" index: true priority: high
    -   file: "docs/DDR_Technical_Report.md" index: true priority: high
    -   file: "docs/DDR.rst" index: true priority: medium watch: true # Re-index on changes

    indexing: strategy: semantic_chunks chunk_size: 1000 overlap: 200 embedding_model: "text-embedding-3-small"

-   name: glossary type: controlled_vocabulary source: "docs/ddr_meta_standard.txt#glossary" enforcement: strict

-   name: code_examples type: example_library sources:

    -   directory: "examples/features/" pattern: "*.py"
    -   directory: "tests/fixtures/" pattern: "test_*.json"

evaluations: load_from: - "evaluations/*.yaml"

continuous_evaluation: enabled: true on_events: - commit - pull_request - manual_trigger

```
quick_suite:
  - classification_accuracy
  - traceability_completeness
  - anti_pattern_detection_rate

full_suite:
  schedule: "0 2 * * *"  # Daily at 2 AM
  include_all: true

```

ui_integration: panels: - name: "DDR Navigator" type: tree_view content: documentation_hierarchy actions: - create_tag - update_tag - view_traceability - validate_section

```
- name: "Traceability Graph"
  type: graph_visualization
  content: dependency_graph
  interactions:
    - click_node: view_tag_details
    - hover_edge: show_citation_context

- name: "Validation Dashboard"
  type: metrics_panel
  content: real_time_validation
  widgets:
    - orphan_count
    - broken_citations
    - anti_pattern_violations
    - manifest_status

```

commands: - command: "DDR: Classify Information" agent: DDR_Orchestrator tool: classify_information shortcut: "Ctrl+Shift+C"

```
- command: "DDR: Create Feature Documentation"
  workflow: complete_feature_documentation
  shortcut: "Ctrl+Shift+F"

- command: "DDR: Validate Traceability"
  agent: Traceability_Auditor
  workflow: comprehensive_audit
  shortcut: "Ctrl+Shift+V"

- command: "DDR: Generate Code Stub"
  agent: ISP_CodeGenerator
  workflow: create_isp_from_tdd
  shortcut: "Ctrl+Shift+G"

```

context_awareness: active_document_analysis: enabled: true triggers: - on_file_open: detect_tier_from_content - on_selection: suggest_parent_tags - on_save: validate_tier_compliance

suggestions: - context: "editing_tag_content" agent: tier_specific_agent suggestion_type: auto_complete_citations

```
- context: "creating_new_tag"
  agent: DDR_Orchestrator
  suggestion_type: next_available_id

- context: "viewing_tag"
  agent: Traceability_Auditor
  suggestion_type: show_dependency_chain

```

automation: git_hooks: pre_commit: - run_quick_validation - check_manifest_accuracy - detect_anti_patterns

```
pre_push:
  - run_full_validation_suite
  - generate_traceability_report

```

on_file_change: pattern: "docs/DDR.rst" actions: - set_manifest_dirty - notify_affected_agents - trigger_incremental_validation

export_formats:

-   format: restructuredtext file: "docs/DDR.rst" template: "templates/ddr_main.rst"

-   format: markdown file: "docs/DDR.md" conversion: pandoc

-   format: html file: "docs/DDR.html" theme: sphinx_rtd_theme

-   format: pdf file: "docs/DDR.pdf" engine: xelatex

-   format: json file: "exports/ddr_machine_readable.json" structure: tag_hierarchy


version_control: tag_versioning: enabled: true strategy: immutable_ids deprecation_marking: true

migration_tracking: enabled: true log_file: "migrations/ddr_changes.log"

reconciliation_history: enabled: true retention_days: 90

~~~


---


### 27.7.2 Custom UI Components

**File:** `.antigravity/ui/tag_editor.yaml`
~~~yaml
name: DDR_Tag_Editor
version: "1.0.0"
description: Custom UI component for editing DDR tags with real-time validation

component:
  type: editor_panel
  layout: vertical

  sections:
    - section: tag_metadata
      label: "Tag Metadata"
      layout: form

      fields:
        - name: tag_id
          type: text
          label: "Tag ID"
          readonly: true
          computed: auto_generate_next_id
          format: "|{tier}-{block_id}|"

        - name: tier
          type: select
          label: "Tier"
          options:
            - value: BRD
              label: "BRD - Business Requirements"
              color: "#e1f5ff"
            - value: NFR
              label: "NFR - Non-Functional Requirements"
              color: "#fff3e0"
            - value: FSD
              label: "FSD - Feature Specifications"
              color: "#f3e5f5"
            - value: SAD
              label: "SAD - System Architecture"
              color: "#e8f5e9"
            - value: ICD
              label: "ICD - Interface Contracts"
              color: "#fce4ec"
            - value: TDD
              label: "TDD - Technical Design"
              color: "#fff9c4"
            - value: ISP
              label: "ISP - Implementation Stubs"
              color: "#f1f8e9"
          on_change: update_validation_rules

        - name: parent_tags
          type: tag_picker
          label: "Parent Tags (Citations)"
          multiple: true
          filter: valid_parent_tiers
          validation: require_at_least_one
          helper_text: "Select parent tags this requirement traces to"

    - section: content_editor
      label: "Content"
      layout: vertical
      fields:
        - name: content
          type: rich_text
          label: "Tag Content"
          syntax_highlighting: restructuredtext
          live_validation: true
          validators:
            - tier_compliance
            - glossary_check
            - anti_pattern_detection
          assistance:
            - type: auto_suggest
              trigger: "typing"
              agent: tier_specific_agent
            - type: format_helper
              show: formatting_toolbar
              options:
                - bold
                - italic
                - code_block
                - citation_link

    - section: validation_panel
      label: "Validation Status"
      layout: horizontal
      collapsible: true
      widgets:
        - widget: validation_badge
          data_source: real_time_validation
          states:
            - status: valid
              icon: "✅"
              color: green
              message: "All validations passed"
            - status: warning
              icon: "⚠️"
              color: yellow
              message: "${warning_count} warnings detected"
            - status: error
              icon: "❌"
              color: red
              message: "${error_count} errors must be fixed"
        - widget: validation_details
          type: expandable_list
          items: validation_results
          template: |
            [${severity}] ${rule_name}: ${message}
            Fix: ${suggestion}

    - section: traceability_preview
      label: "Traceability Chain"
      layout: vertical
      collapsible: true
      widgets:
        - widget: dependency_graph
          type: mermaid_diagram
          data_source: trace_to_root(current_tag)
          interactive: true
          actions:
            - click_node: navigate_to_tag
        - widget: impact_analysis
          type: table
          columns:
            - name: child_tag
              label: "Affected Child Tags"
            - name: tier
              label: "Tier"
            - name: impact
              label: "Impact Type"
          data_source: find_tags_citing(current_tag)

  actions:
    - action: save_tag
      icon: "💾"
      shortcut: "Ctrl+S"
      workflow:
        - validate_all_rules
        - if_validation_passed:
            - commit_tag_to_documentation
            - update_manifest
            - notify_dependent_tags
        - if_validation_failed:
            - show_error_dialog
            - prevent_save
    - action: preview_formatted
      icon: "👁️"
      shortcut: "Ctrl+P"
      workflow:
        - render_restructuredtext
        - open_preview_panel
    - action: view_full_chain
      icon: "🔗"
      shortcut: "Ctrl+T"
      workflow:
        - invoke_agent: Traceability_Auditor
        - workflow: trace_tag_to_root
        - display_in_graph_panel
    - action: suggest_improvements
      icon: "💡"
      shortcut: "Ctrl+I"
      workflow:
        - invoke_agent: tier_specific_agent
        - analyze_content_quality
        - show_suggestions_panel

  real_time_features:
    - feature: live_validation
      debounce_ms: 500
      validators:
        - name: tier_compliance
          agent: tier_specific_agent
          rule: validate_tier_compliance
          display: inline_errors
        - name: glossary_check
          tool: check_controlled_vocabulary
          display: highlight_violations
        - name: citation_syntax
          regex: '← \|[A-Z]{3}-\d+(\.\d+)?\|'
          display: syntax_highlighting
    - feature: auto_save
      enabled: true
      interval_seconds: 30
      condition: content_changed
    - feature: collaboration
      enabled: true
      show_cursors: true
      show_selections: true
      conflict_resolution: last_write_wins

  keyboard_shortcuts:
    - key: "Ctrl+Space"
      action: trigger_autocomplete
      context: content_editor
    - key: "Alt+Up"
      action: navigate_to_parent_tag
      context: any
    - key: "Alt+Down"
      action: navigate_to_first_child
      context: any
    - key: "Ctrl+Shift+V"
      action: validate_current_tag
      context: any
    - key: "Ctrl+Shift+R"
      action: refactor_tag
      context: any

~~~

---

## 27.8 Example Usage Scenarios

### 27.8.1 Scenario 1: Developer Documents New Feature

**User Action:** Developer wants to add "Voice Emotion Detection" feature

**Antigravity Interaction:**
/"
      - "workflows/"

tools:
  load_from:
    - "tools/*.yaml"

  global_tools:
    - tag_operations
    - validation_tools
    - manifest_management

workflows:
  load_from:
    - "workflows/*.yaml"

  featured_workflows:
    - complete_feature_documentation
    - orphan_resolution
    - refactoring_migration
    - comprehensive_audit

knowledge_bases:
  - name: ddr_specification
    type: reference_documentation
    sources:
      - file: "docs/ddr_meta_standard.txt"
        index: true
        priority: high
      - file: "docs/DDR_Technical_Report.md"
        index: true
        priority: high
      - file: "docs/DDR.rst"
        index: true
        priority: medium
        watch: true  # Re-index on changes

    indexing:
      strategy: semantic_chunks
      chunk_size: 1000
      overlap: 200
      embedding_model: "text-embedding-3-small"

  - name: glossary
    type: controlled_vocabulary
    source: "docs/ddr_meta_standard.txt#glossary"
    enforcement: strict

  - name: code_examples
    type: example_library
    sources:
      - directory: "examples/features/"
        pattern: "*.py"
      - directory: "tests/fixtures/"
        pattern: "test_*.json"

evaluations:
  load_from:
    - "evaluations/*.yaml"

  continuous_evaluation:
    enabled: true
    on_events:
      - commit
      - pull_request
      - manual_trigger

    quick_suite:
      - classification_accuracy
      - traceability_completeness
      - anti_pattern_detection_rate

    full_suite:
      schedule: "0 2 * * *"  # Daily at 2 AM
      include_all: true

ui_integration:
  panels:
    - name: "DDR Navigator"
      type: tree_view
      content: documentation_hierarchy
      actions:
        - create_tag
        - update_tag
        - view_traceability
        - validate_section

    - name: "Traceability Graph"
      type: graph_visualization
      content: dependency_graph
      interactions:
        - click_node: view_tag_details
        - hover_edge: show_citation_context

    - name: "Validation Dashboard"
      type: metrics_panel
      content: real_time_validation
      widgets:
        - orphan_count
        - broken_citations
        - anti_pattern_violations
        - manifest_status

  commands:
    - command: "DDR: Classify Information"
      agent: DDR_Orchestrator
      tool: classify_information
      shortcut: "Ctrl+Shift+C"

    - command: "DDR: Create Feature Documentation"
      workflow: complete_feature_documentation
      shortcut: "Ctrl+Shift+F"

    - command: "DDR: Validate Traceability"
      agent: Traceability_Auditor
      workflow: comprehensive_audit
      shortcut: "Ctrl+Shift+V"

    - command: "DDR: Generate Code Stub"
      agent: ISP_CodeGenerator
      workflow: create_isp_from_tdd
      shortcut: "Ctrl+Shift+G"

context_awareness:
  active_document_analysis:
    enabled: true
    triggers:
      - on_file_open: detect_tier_from_content
      - on_selection: suggest_parent_tags
      - on_save: validate_tier_compliance

  suggestions:
    - context: "editing_tag_content"
      agent: tier_specific_agent
      suggestion_type: auto_complete_citations

    - context: "creating_new_tag"
      agent: DDR_Orchestrator
      suggestion_type: next_available_id

    - context: "viewing_tag"
      agent: Traceability_Auditor
      suggestion_type: show_dependency_chain

automation:
  git_hooks:
    pre_commit:
      - run_quick_validation
      - check_manifest_accuracy
      - detect_anti_patterns

    pre_push:
      - run_full_validation_suite
      - generate_traceability_report

  on_file_change:
    pattern: "docs/DDR.rst"
    actions:
      - set_manifest_dirty
      - notify_affected_agents
      - trigger_incremental_validation

export_formats:
  - format: restructuredtext
    file: "docs/DDR.rst"
    template: "templates/ddr_main.rst"

  - format: markdown
    file: "docs/DDR.md"
    conversion: pandoc

  - format: html
    file: "docs/DDR.html"
    theme: sphinx_rtd_theme

  - format: pdf
    file: "docs/DDR.pdf"
    engine: xelatex

  - format: json
    file: "exports/ddr_machine_readable.json"
    structure: tag_hierarchy

version_control:
  tag_versioning:
    enabled: true
    strategy: immutable_ids
    deprecation_marking: true

  migration_tracking:
    enabled: true
    log_file: "migrations/ddr_changes.log"

  reconciliation_history:
    enabled: true
    retention_days: 90
```

---

### 27.7.2 Custom UI Components

**File:** `.antigravity/ui/tag_editor.yaml`

```yaml
name: DDR_Tag_Editor
version: "1.0.0"
description: Custom UI component for editing DDR tags with real-time validation

component:
  type: editor_panel
  layout: vertical

  sections:
    - section: tag_metadata
      label: "Tag Metadata"
      layout: form

      fields:
        - name: tag_id
          type: text
          label: "Tag ID"
          readonly: true
          computed: auto_generate_next_id
          format: "|{tier}-{block_id}|"

        - name: tier
          type: select
          label: "Tier"
          options:
            - value: BRD
              label: "BRD - Business Requirements"
              color: "#e1f5ff"
            - value: NFR
              label: "NFR - Non-Functional Requirements"
              color: "#fff3e0"
            - value: FSD
              label: "FSD - Feature Specifications"
              color: "#f3e5f5"
            - value: SAD
              label: "SAD - System Architecture"
              color: "#e8f5e9"
            - value: ICD
              label: "ICD - Interface Contracts"
              color: "#fce4ec"
            - value: TDD
              label: "TDD - Technical Design"
              color: "#fff9c4"
            - value: ISP
              label: "ISP - Implementation Stubs"
              color: "#f1f8e9"
          on_change: update_validation_rules

        - name: parent_tags
          type: tag_picker
          label: "Parent Tags (Citations)"
          multiple: true
          filter: valid_parent_tiers
          validation: require_at_least_one
          helper_text: "Select parent tags this requirement traces to"

    - section: content_editor
      label: "Content"
      layout: vertical

      fields:
        - name: content
          type: rich_text
          label: "Tag Content"
          syntax_highlighting: restructuredtext
          live_validation: true
          validators:
            - tier_compliance
            - glossary_check
            - anti_pattern_detection

          assistance:
            - type: auto_suggest
              trigger: "typing"
              agent: tier_specific_agent

            - type: format_helper
              show: formatting_toolbar
              options:
                - bold
                - italic
                - code_block
                - citation_link

    - section: validation_panel
      label: "Validation Status"
      layout: horizontal
      collapsible: true

      widgets:
        - widget: validation_badge
          data_source: real_time_validation
          states:
            - status: valid
              icon: "✅"
              color: green
              message: "All validations passed"

            - status: warning
              icon: "⚠️"
              color: yellow
              message: "${warning_count} warnings detected"

            - status: error
              icon: "❌"
              color: red
              message: "${error_count} errors must be fixed"

        - widget: validation_details
          type: expandable_list
          items: validation_results
          template: |
            [${severity}] ${rule_name}: ${message}
            Fix: ${suggestion}

    - section: traceability_preview
      label: "Traceability Chain"
      layout: vertical
      collapsible: true

      widgets:
        - widget: dependency_graph
          type: mermaid_diagram
          data_source: trace_to_root(current_tag)
          interactive: true
          actions:
            - click_node: navigate_to_tag

        - widget: impact_analysis
          type: table
          columns:
            - name: child_tag
              label: "Affected Child Tags"
            - name: tier
              label: "Tier"
            - name: impact
              label: "Impact Type"
          data_source: find_tags_citing(current_tag)

actions:
  - action: save_tag
    icon: "💾"
    shortcut: "Ctrl+S"

    workflow:
      - validate_all_rules
      - if_validation_passed:
          - commit_tag_to_documentation
          - update_manifest
          - notify_dependent_tags
      - if_validation_failed:
          - show_error_dialog
          - prevent_save

  - action: preview_formatted
    icon: "👁️"
    shortcut: "Ctrl+P"

    workflow:
      - render_restructuredtext
      - open_preview_panel

  - action: view_full_chain
    icon: "🔗"
    shortcut: "Ctrl+T"

    workflow:
      - invoke_agent: Traceability_Auditor
      - workflow: trace_tag_to_root
      - display_in_graph_panel

  - action: suggest_improvements
    icon: "💡"
    shortcut: "Ctrl+I"

    workflow:
      - invoke_agent: tier_specific_agent
      - analyze_content_quality
      - show_suggestions_panel

real_time_features:
  - feature: live_validation
    debounce_ms: 500

    validators:
      - name: tier_compliance
        agent: tier_specific_agent
        rule: validate_tier_compliance
        display: inline_errors

      - name: glossary_check
        tool: check_controlled_vocabulary
        display: highlight_violations

      - name: citation_syntax
        regex: '← \|[A-Z]{3}-\d+(\.\d+)?\|'
        display: syntax_highlighting

  - feature: auto_save
    enabled: true
    interval_seconds: 30
    condition: content_changed

  - feature: collaboration
    enabled: true
    show_cursors: true
    show_selections: true
    conflict_resolution: last_write_wins

keyboard_shortcuts:
  - key: "Ctrl+Space"
    action: trigger_autocomplete
    context: content_editor

  - key: "Alt+Up"
    action: navigate_to_parent_tag
    context: any

  - key: "Alt+Down"
    action: navigate_to_first_child
    context: any

  - key: "Ctrl+Shift+V"
    action: validate_current_tag
    context: any

  - key: "Ctrl+Shift+R"
    action: refactor_tag
    context: any
```

---


## 27.8 Example Usage Scenarios

### 27.8.1 Scenario 1: Developer Documents New Feature

**User Action:** Developer wants to add "Voice Emotion Detection" feature

**Antigravity Interaction:**
```
Developer: "Document new feature: Voice Emotion Detection"

DDR_Orchestrator: Initiating complete_feature_documentation workflow..


━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Stage 1/9: Define Business Case
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

BRD_Strategist: Let's start by understanding the business value.
What user pain point or market opportunity does Voice Emotion Detection address?

Developer: Users want more empathetic responses. Current assistant doesn't recognize emotional state, leading to tone-deaf interactions.

BRD_Strategist: Excellent. Who are the primary stakeholders?

Developer: End users seeking emotional intelligence, and enterprise customers in healthcare/therapy applications.

BRD_Strategist: What are the success metrics?

Developer: User satisfaction score increase by 25%, reduction in negative feedback by 40%, enterprise adoption in healthcare vertical.

BRD_Strategist: ✅ Creating BRD tags...

Generated:

|BRD-18|: "Emotional Intelligence Enhancement"

Enable empathetic, context-aware responses to improve user satisfaction

and expand into healthcare market vertical.

Success Metrics:

- User satisfaction: +25% (current: 3.2/5 → target: 4.0/5)

- Negative feedback: -40% reduction

- Healthcare enterprise adoption: ≥15 POCs within 6 months



Validation: ✅ PASS (technology-agnostic, measurable metrics)



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Stage 2/9: Establish Constraints & Limits

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━



NFR_Enforcer: Based on |BRD-18|, let's define technical constraints.



What are the performance requirements?



Developer: Real-time analysis (<100ms latency), CPU-only (can't use GPU during

LLM inference), accuracy ≥80% (F1 score on standard emotion datasets).



NFR_Enforcer: Resource limits?



Developer: Model size <200MB, RAM <500MB during execution. Must run in Audio

Process (CPU-bound constraint).



NFR_Enforcer: ✅ Creating NFR tags...



Generated:

|NFR-19| ← |BRD-18|: "Emotion Detection Constraints"

|NFR-19.1|: Latency: <100ms per audio chunk analysis.

|NFR-19.2|: Accuracy: F1 score ≥0.80 on IEMOCAP dataset.

|NFR-19.3|: Model size: <200MB (CPU-optimized model).

|NFR-19.4|: Memory: <500MB RAM during execution.

|NFR-19.5|: Hardware: CPU-only (Audio Process, AMD Ryzen 9 5900X).



Validation: ✅ PASS (measurable constraints, hardware-aware)



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

[Workflow continues through all 9 stages...]

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━



Stage 9/9: Update Reconciliation Manifests

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━



Manifest_Manager: Synchronizing all manifests...



Updated:

- brd-root: +1 tag (total: 19)

- nfr-root: +5 tags (total: 94)

- fsd-root: +7 tags (total: 127)

- sad-root: +3 tags (total: 78)

- icd-root: +4 tags (total: 85)

- tdd-root: +6 tags (total: 104)

- isp-root: +6 tags (total: 98)



All manifests: ✅ SYNCHRONIZED



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

✅ Feature Documentation Complete!

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━



Total: 32 new tags created across 7 tiers

Traceability: ✅ All chains validated (max depth: 7)

Anti-patterns: 0 violations detected



Generated artifacts:

📄 Documentation: docs/DDR.rst (updated)

💻 Code stubs: src/emotion_detection/

- EmotionDetector.py

- AudioFeatureExtractor.py

📊 Diagrams: docs/diagrams/emotion_detection/

- topology.mmd

- traceability.mmd



Next steps:

1. Review implementation stubs: src/emotion_detection/

2. Implement logic (replace `pass` with actual code)

3. Run tests: pytest tests/test_emotion_detection.py

4. Commit changes: git add docs/ src/

```



---



### 27.8.2 Scenario 2: Fixing Orphaned Tag



**User Action:** Developer notices |FSD-21.3| has no parent citation



**Antigravity Interaction:**



```

[Antigravity detects orphan during background validation]



Orphan_Detective: ⚠️ Orphan tag detected: |FSD-21.3|



Content preview:

"System analyzes user speech prosody to detect emotional state

(happy, sad, angry, neutral)."



This tag has no parent citation (← |PARENT| missing).



Would you like me to resolve this automatically?



Developer: Yes, please resolve.



Orphan_Detective: Analyzing tag content to determine resolution direction...



Classification: UPWARD (implementation detail without business justification)



I'll synthesize a parent tag in the NFR tier to establish the constraint.



Proposed parent:

|NFR-19.6| ← |BRD-18|: "Emotion Classification"

System must detect minimum 4 emotional states (happy, sad, angry, neutral)

with discrete classification (not continuous valence/arousal).



Does this accurately capture the constraint that justifies |FSD-21.3|?



Developer: Yes, but also add "real-time" constraint.



Orphan_Detective: Updated proposal:

|NFR-19.6| ← |BRD-18|: "Emotion Classification Requirements"

System must classify audio into minimum 4 emotional states (happy, sad,

angry, neutral) in real-time (<100ms latency per chunk).



Developer: Perfect!



Orphan_Detective: ✅ Created |NFR-19.6|



Now updating |FSD-21.3| with citation...



Updated:

|FSD-21.3| ← |NFR-19.6|: "System analyzes user speech prosody..."



Validation:

✅ Citation chain complete: |FSD-21.3| → |NFR-19.6| → |BRD-18|

✅ No more orphans in FSD-21 block



Manifest updated:

- nfr-root: +1 tag (|NFR-19.6| added to inventory)

- Integrity status: CLEAN



Would you like me to check for other orphans in the documentation?



Developer: Yes, run full audit.



Orphan_Detective: Initiating comprehensive audit...

[Workflow: comprehensive_audit runs]

```



---



### 27.8.3 Scenario 3: Real-Time Validation During Editing



**User Action:** Developer edits |BRD-5| content in Tag Editor



**Antigravity Interaction:**



```

[Developer opens Tag Editor for |BRD-5|]



Tag Editor: Loaded |BRD-5|: "High-level Scope"



[Developer types: "Use ZeroMQ for multi-process communication"]



[500ms debounce expires, live validation triggers]



BRD_Strategist: ⚠️ Tier Violation Detected



Rule: BRD_R1_Technology_Agnostic

Severity: ERROR



Violation: Technology reference in BRD tier

Forbidden term detected: "ZeroMQ"



Suggestion: Abstract to business capability

❌ "Use ZeroMQ for multi-process communication"

✅ "Enable fault-tolerant inter-process communication"



[Red underline appears under "ZeroMQ" in editor]



[Developer clicks on underlined text]



Quick Fix Menu:

1. ✅ Replace with: "fault-tolerant communication"

2. ✅ Replace with: "multi-process architecture"

3. 🔧 Move to SAD tier (create |SAD-X| with technology detail)

4. ℹ️ Learn more about BRD tier rules



[Developer selects option 1]



Tag Editor: Content updated:

"Enable fault-tolerant inter-process communication"



BRD_Strategist: ✅ Validation passed

No tier violations detected.



[Green checkmark appears in validation panel]



[Developer continues editing...]



[Developer adds: "Target: 99.9% uptime SLA"]



BRD_Strategist: ✅ Excellent!

Added measurable success metric (99.9% uptime).



Suggestion: Consider adding context

- What's the current uptime?

- What's the business impact of achieving this SLA?



[Suggestion appears as hint in editor sidebar]

```



---



## 27.9 Benefits Summary



### 27.9.1 For Human Developers



**Reduced Cognitive Load:**

- Agents handle tier classification automatically

- Real-time validation catches mistakes immediately

- Suggested parent tags eliminate manual searching



**Faster Documentation:**

- Complete feature workflow: 15-20 minutes (vs. 2-3 hours manual)

- Automated stub generation from blueprints

- Pre-filled traceability chains



**Higher Quality:**

- 100% traceability coverage (automated validation)

- Zero anti-pattern violations (real-time detection)

- Consistent terminology (glossary enforcement)



### 27.9.2 For AI Agents



**Structured Context:**

- Clear tier boundaries enable specialized expertise

- Tag-based retrieval provides precise context windows

- Reconciliation manifests track system state



**Verifiable Outputs:**

- Automated evaluation against ground truth

- Continuous validation feedback loop

- Measurable quality metrics



**Scalable Collaboration:**

- Agent hierarchy mirrors documentation hierarchy

- Parallel processing (BRD + NFR agents work simultaneously on different features)

- Conflict-free workflows (strict causal ordering)



### 27.9.3 For Project Maintainability



**Living Documentation:**

- Auto-updating manifests track inventory

- Dirty flags signal when reconciliation needed

- Version history preserved via immutable IDs



**Onboarding Efficiency:**

- New developers use Tag Navigator to explore

- Traceability graphs show "why" behind "what"

- Code stubs with implementation guidance



**Audit Compliance:**

- 100% traceable from code → business requirement

- Automated compliance reports

- Change history with rationale tracking



---



## 27.10 Conclusion



The Antigravity agent asset definitions transform the MAGGIE DDR from a static documentation framework into a **dynamic, AI-assisted knowledge management system**. By encoding the rules, workflows, and validation logic into agent personas and tools, we enable:



1.  **Automated Classification:** Unstructured information instantly routed to appropriate tier

2.  **Real-Time Validation:** Mistakes caught during authoring, not in review

3.  **Intelligent Assistance:** Context-aware suggestions based on current tier and content

4.  **Complete Traceability:** Automated chain validation from ISP code stubs to BRD business cases

5.  **Scalable Workflows:** End-to-end feature documentation in minutes, not hours



This integration creates a **human-AI collaborative development environment** where:

-  **Humans** provide creative direction, domain expertise, and strategic decisions

-  **AI Agents** enforce constraints, maintain consistency, and automate tedious tasks

-  **The DDR** serves as the shared knowledge graph connecting both



The result is documentation that is not merely comprehensive, but **actively maintained, continuously validated, and genuinely useful** as both a human reference and a machine-parseable specification for LLM-assisted development.



---
