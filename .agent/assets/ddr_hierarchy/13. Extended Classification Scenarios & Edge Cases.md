
## 13. Extended Classification Scenarios & Edge Cases

### 13.1 Multi-Tier Decomposition Patterns

#### Pattern 1: Security Requirement Cascade

**Business Driver (BRD):**

~~~rst
.. brd:: Data Sovereignty Compliance
   :id: BRD-11

   Ensure all user data remains within jurisdictional boundaries to comply with GDPR, CCPA, and healthcare data protection regulations. This enables deployment in regulated industries (healthcare, finance, government).
~~~

-   **Abstraction:** Regulatory compliance as competitive advantage
-   **Stakeholder:** Legal/Compliance teams, Enterprise customers

**System Constraint (NFR):**

~~~rst
.. nfr:: Data Locality Enforcement
   :id: NFR-10
   :links: BRD-11

.. nfr:: No network transmission beyond localhost (127.0.0.1).
   :id: NFR-10.1
   :links: NFR-10

.. nfr:: No filesystem access outside designated data directory.
   :id: NFR-10.2
   :links: NFR-10

.. nfr:: All model weights must be locally stored (<5GB total).
   :id: NFR-10.3
   :links: NFR-10

.. nfr:: Encryption at rest: AES-256 for persistent logs/state.
   :id: NFR-10.4
   :links: NFR-10
~~~

-   **Abstraction:** Technical boundaries enforcing business requirement
-   **Measurable:** File paths, encryption standards, size limits

**Functional Specification (FSD):**

~~~rst
.. fsd:: Secure Data Handling
   :id: FSD-11
   :links: NFR-10

.. fsd:: Core validates all file paths against whitelist before access.
   :id: FSD-11.1
   :links: FSD-11

.. fsd:: LogServer encrypts files before writing to disk.
   :id: FSD-11.2
   :links: FSD-11

.. fsd:: Runtime rejects model load requests outside approved directory.
   :id: FSD-11.3
   :links: FSD-11

.. fsd:: UI displays data locality status indicator (green="local only").
   :id: FSD-11.4
   :links: FSD-11
~~~

-   **Abstraction:** Observable system behaviors enforcing constraints
-   **User-Facing:** Status indicators, error messages

**Architecture (SAD):**

~~~rst
.. sad:: Path Validation Strategy
   :id: SAD-9
   :links: FSD-11.1

.. sad:: Pattern: Whitelist validator with chroot-style restriction.
   :id: SAD-9.1
   :links: SAD-9

.. sad:: Core maintains allowed_paths registry (loaded from config).
   :id: SAD-9.2
   :links: SAD-9

.. sad:: All Services query Core before filesystem operations.
   :id: SAD-9.3
   :links: SAD-9
~~~

-   **Abstraction:** Architectural mechanism implementing validation
-   **Technology-Neutral:** Doesn't specify validation library

**Data Contract (ICD):**

~~~rst
.. icd:: Security Configuration Schema
   :id: ICD-7
   :links: SAD-9.2

   .. code-block:: yaml

      security:
        allowed_directories:
          - "./models"
          - "./logs"
          - "./extensions"
        encryption:
          algorithm: "AES-256-CBC"
          key_derivation: "PBKDF2"
          iterations: 100000
~~~

-   **Abstraction:** Exact configuration structure
-   **Validation:** YAML schema with required fields

**Component Design (TDD):**

~~~rst
.. tdd:: Component: PathValidator
   :id: TDD-6
   :links: ICD-7, SAD-9.1

.. tdd:: Class: PathValidator
   :id: TDD-6.1
   :links: TDD-6

.. tdd:: Dependencies: pathlib, os
   :id: TDD-6.2
   :links: TDD-6

.. tdd:: Method: is_allowed(path: Path) -> bool
   :id: TDD-6.3
   :links: TDD-6

.. tdd:: Internal: _normalize_path() resolves symlinks, checks whitelist
   :id: TDD-6.4
   :links: TDD-6

.. tdd:: Raises: SecurityError if path outside allowed directories
   :id: TDD-6.5
   :links: TDD-6
~~~

-   **Abstraction:** Class structure without implementation logic
-   **Contract:** Method signatures, exceptions

**Code Stub (ISP):**

~~~python
# |ISP-7|: "Path Validator Implementation Stub"

from pathlib import Path
from typing import List

class PathValidator:
    """
    Validates filesystem paths against whitelist.

    Implements
    ----------
    |TDD-6|, |FSD-11.1|

    Security
    --------
    |NFR-10.2|: Prevents directory traversal attacks

    Attributes
    ----------
    allowed_dirs : List[Path]
        Whitelisted directories from |ICD-7|
    """

    def __init__(self, allowed_dirs: List[str]):
        """
        Initialize validator with allowed directories.

        Parameters
        ----------
        allowed_dirs : List[str]
            Paths from security.allowed_directories (|ICD-7|)

        Implementation Notes
        --------------------
        1. Convert strings to Path objects
        2. Resolve to absolute paths (resolve symlinks)
        3. Store in self.allowed_dirs

        References
        ----------
        |TDD-6.2|, |SAD-9.2|
        """
        pass

    def is_allowed(self, path: Path) -> bool:
        """
        Check if path is within allowed directories.

        Parameters
        ----------
        path : Path
            Path to validate

        Returns
        -------
        bool
            True if path is within whitelist

        Raises
        ------
        SecurityError
            If path attempts directory traversal (|TDD-6.5|)

        Implementation Notes
        --------------------
        1. Resolve path to absolute (handle .., symlinks)
        2. Check if any allowed_dir is parent of path
        3. Use path.is_relative_to() for safety

        References
        ----------
        |TDD-6.3|, |FSD-11.1|
        """
        pass
~~~

**Traceability Chain:**

~~~rst
.. isp:: Data Locality Path Validator
   :id: ISP-7
   :links: TDD-6

.. tdd:: PathValidator Component
   :id: TDD-6
   :links: ICD-7, SAD-9

.. icd:: security_config
   :id: ICD-7
   :links: SAD-9

.. sad:: path_validation_strategy
   :id: SAD-9
   :links: FSD-11

.. fsd:: secure_data_handling
   :id: FSD-11
   :links: NFR-10

.. nfr:: data_locality_enforcement
   :id: NFR-10
   :links: BRD-11
~~~

----------

#### Pattern 2: Performance Optimization Cascade

**Business Goal (BRD):**

~~~rst
.. brd:: Real-Time Conversational Experience
   :id: BRD-12

   Enable fluid, human-like conversational flow with minimal perceived latency to increase user engagement and reduce abandonment rates (target: <5% session abandonment due to lag).
~~~

**Performance Constraint (NFR):**

~~~rst
.. nfr:: End-to-End Latency Budget
   :id: NFR-11
   :links: BRD-12

.. nfr:: Voice-to-Response (E2E): ≤3s (95th percentile).
   :id: NFR-11.1
   :links: NFR-11

.. nfr:: Breakdown: STT(500ms) + LLM(1500ms) + TTS(800ms) + IPC(200ms).
   :id: NFR-11.2
   :links: NFR-11

.. nfr:: First-token latency (LLM): ≤200ms.
   :id: NFR-11.3
   :links: NFR-11

.. nfr:: GPU utilization: ≥80% during inference (avoid idle waste).
   :id: NFR-11.4
   :links: NFR-11
~~~

**Feature Specification (FSD):**

~~~rst
.. fsd:: Progressive Response Rendering
   :id: FSD-12
   :links: NFR-11

.. fsd:: UI displays "thinking" indicator within 100ms of user input.
   :id: FSD-12.1
   :links: FSD-12

.. fsd:: LLM tokens stream to UI as generated (no buffer wait).
   :id: FSD-12.2
   :links: FSD-12

.. fsd:: TTS begins synthesis after first sentence (≥5 tokens).
   :id: FSD-12.3
   :links: FSD-12

.. fsd:: Audio playback starts before full synthesis completes.
   :id: FSD-12.4
   :links: FSD-12
~~~

**Architecture (SAD):**

~~~rst
.. sad:: Streaming Architecture
   :id: SAD-10
   :links: FSD-12.2

.. sad:: Pattern: Producer-Consumer with bounded queues.
   :id: SAD-10.1
   :links: SAD-10

.. sad:: LLM yields tokens to queue (non-blocking generation).
   :id: SAD-10.2
   :links: SAD-10

.. sad:: UI consumes tokens via polling (100ms interval).
   :id: SAD-10.3
   :links: SAD-10

.. sad:: Back-pressure: LLM pauses if queue full (size=50 tokens).
   :id: SAD-10.4
   :links: SAD-10
~~~

**Data Contract (ICD):**

~~~rst
.. icd:: Streaming Token Schema
   :id: ICD-8
   :links: SAD-10.2

   .. code-block:: json

      {
        "type": "token_delta" | "stream_end",
        "request_id": "uuid-v4",
        "sequence_num": 0,
        "token": "string",
        "cumulative_text": "string"
      }
~~~

**Component Design (TDD):**

~~~rst
.. tdd:: Component: LLMStreamer
   :id: TDD-7
   :links: ICD-8, SAD-10.2

.. tdd:: Class: LLMStreamer (runs in Runtime Process)
   :id: TDD-7.1
   :links: TDD-7

.. tdd:: Dependencies: onnxruntime-gpu, queue, threading
   :id: TDD-7.2
   :links: TDD-7

.. tdd:: Method: generate_stream(prompt: str, request_id: str) -> Generator
   :id: TDD-7.3
   :links: TDD-7

.. tdd:: Internal: token_queue (maxsize=50 per SAD-10.4)
   :id: TDD-7.4
   :links: TDD-7

.. tdd:: Sends token_delta messages via ServiceClient for each yield
   :id: TDD-7.5
   :links: TDD-7
~~~

**Code Stub (ISP):**

~~~python
# |ISP-8|: "LLM Streaming Implementation Stub"

from typing import Generator
import queue
import threading

class LLMStreamer:
    """
    Streaming text generation with back-pressure control.

    Implements
    ----------
    |TDD-7|, |FSD-12.2|

    Performance
    -----------
    |NFR-11.3|: First token within 200ms
    |NFR-11.4|: Maintains ≥80% GPU utilization

    Attributes
    ----------
    token_queue : queue.Queue
        Bounded queue for back-pressure (|SAD-10.4|)
    """

    def __init__(self, model_session, client: ServiceClient):
        """
        Initialize streamer with ONNX session and IPC client.

        Parameters
        ----------
        model_session : ort.InferenceSession
            Pre-loaded ONNX model
        client : ServiceClient
            For sending token_delta messages

        References
        ----------
        |TDD-7.2|
        """
        self.token_queue = queue.Queue(maxsize=50)
        pass

    def generate_stream(self, prompt: str, request_id: str) -> Generator[str, None, None]:
        """
        Generate tokens and yield to consumer.

        Parameters
        ----------
        prompt : str
            User input text
        request_id : str
            UUID for correlation (|ICD-8|)

        Yields
        ------
        str
            Individual tokens

        Implementation Notes
        --------------------
        1. Tokenize prompt, prepare ONNX inputs
        2. For each generation step:
           a. Run ONNX inference (single token)
           b. Decode token to string
           c. Construct token_delta message (|ICD-8|)
           d. Send via self.client.send_request()
           e. Yield token to caller
           f. Check if token_queue full (back-pressure)
        3. Send stream_end message after EOS token

        Performance
        -----------
        - First yield MUST occur within 200ms (|NFR-11.3|)
        - Use ort.SessionOptions.graph_optimization_level = 99

        References
        ----------
        |TDD-7.3|, |SAD-10.2|, |FSD-12.2|
        """
        pass
~~~

----------

### 13.2 Conflict Resolution Matrices

#### Scenario: Contradictory Requirements

**Conflict:**

~~~rst
.. nfr:: LLM Inference: <1s average response time.
   :id: NFR-4.3

.. nfr:: All model weights <5GB total (for data sovereignty).
   :id: NFR-10.3

CONFLICT: Quantized models <5GB achieve only ~1.5s inference time on RTX 3080.
~~~

**Resolution Framework:**


| Option | BRD Impact | NFR Changes | FSD Changes | SAD Changes | Risk |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **A: Relax Latency** | Acceptable if <2s | Update NFR-4.3 → <2s | No change | No change | Low user satisfaction |
| **B: Increase Model Size** | Violates BRD-11 | Update NFR-10.3 → <8GB | No change | No change | Regulatory risk |
| **C: Upgrade Hardware** | Cost increase | Update NFR-1.2 → RTX 4090 | No change | No change | Budget impact |
| **D: Hybrid Approach** | Partial compliance | Add NFR-11.5: "Fast mode" | Add FSD-13: "User selects mode" | Update SAD for conditional loading | Complexity increase |

**Recommended: Option D (Hybrid)**

**Updated Documentation:**

~~~rst
.. brd:: Flexible Compliance Modes
   :id: BRD-11.1

   Support both strict compliance (offline, <5GB) and performance mode (relaxed limits) to serve different market segments.

.. nfr:: Model Size Modes
   :id: NFR-11.5
   :links: BRD-11.1

   - Compliance Mode: Models ≤5GB, latency ≤2s
   - Performance Mode: Models ≤12GB, latency ≤1s

.. fsd:: User Mode Selection
   :id: FSD-13
   :links: NFR-11.5

.. fsd:: UI provides mode toggle in settings (requires restart).
   :id: FSD-13.1
   :links: FSD-13

.. fsd:: Core validates hardware capabilities before mode switch.
   :id: FSD-13.2
   :links: FSD-13

.. fsd:: Compliance mode disables network features (strict isolation).
   :id: FSD-13.3
   :links: FSD-13

.. sad:: Conditional Model Loading
   :id: SAD-11
   :links: FSD-13

.. sad:: Config schema includes 'operating_mode' field.
   :id: SAD-11.1
   :links: SAD-11

.. sad:: Runtime selects model manifest based on mode.
   :id: SAD-11.2
   :links: SAD-11
~~~

----------

### 13.3 Cross-Process Feature Mapping

#### Feature: "Conversation History with Semantic Search"

This feature spans all processes and tiers. Map it comprehensively:

**BRD (Business Value):**

~~~rst
.. brd:: Contextual Memory
   :id: BRD-13

   Enable users to reference past conversations without manual note-taking, increasing productivity and reducing repetitive queries (target: 30% reduction in duplicate questions).
~~~

**NFR (Constraints):**

~~~rst
.. nfr:: Memory Subsystem Constraints
   :id: NFR-12
   :links: BRD-13

.. nfr:: Embedding model: <500MB, CPU-only (for continuous background indexing).
   :id: NFR-12.1
   :links: NFR-12

.. nfr:: Vector search: <50ms for 10k entries (HNSW index).
   :id: NFR-12.2
   :links: NFR-12

.. nfr:: Storage: SQLite database, <1GB for 1 year of conversations.
   :id: NFR-12.3
   :links: NFR-12

.. nfr:: Privacy: No cloud sync, all data local.
   :id: NFR-12.4
   :links: NFR-12
~~~

**FSD (Capabilities):**

~~~rst
.. fsd:: Conversation Indexing
   :id: FSD-14
   :links: NFR-12

.. fsd:: After each LLM response, generate embedding (384-dim vector).
   :id: FSD-14.1
   :links: FSD-14

.. fsd:: Store in local vector database (conversation_id, timestamp, text, embedding).
   :id: FSD-14.2
   :links: FSD-14

.. fsd:: User can query: "What did I ask about recipes last week?"
   :id: FSD-14.3
   :links: FSD-14

.. fsd:: System returns top-5 semantic matches with timestamps.
   :id: FSD-14.4
   :links: FSD-14

.. fsd:: Clicking match loads full conversation in UI sidebar.
   :id: FSD-14.5
   :links: FSD-14
~~~

**SAD (Architecture):**

~~~rst
.. sad:: Memory Architecture
   :id: SAD-12
   :links: FSD-14

.. sad:: New Service: MemoryService (CPU-bound, separate process).
   :id: SAD-12.1
   :links: SAD-12

.. sad:: Pattern: Async indexing (POST request, no blocking wait).
   :id: SAD-12.2
   :links: SAD-12

.. sad:: Pattern: Sync search (GET request, blocks UI until results).
   :id: SAD-12.3
   :links: SAD-12

.. sad:: Database: SQLite with FTS5 (full-text) + FAISS (vector).
   :id: SAD-12.4
   :links: SAD-12

.. sad:: Topology
   :id: SAD-12.5
   :links: SAD-12

   Runtime (LLM) → Core → MemoryService (index)
   UI (search) → Core → MemoryService → UI (results)
~~~

**ICD (Contracts):**

~~~rst
.. icd:: Memory Index Request
   :id: ICD-9
   :links: SAD-12.2

   .. code-block:: json

      {
        "command": "memory_index",
        "request_id": "uuid",
        "payload": {
          "conversation_id": "uuid",
          "timestamp": "ISO-8601",
          "text": "full conversation text",
          "speaker": "user" | "assistant"
        }
      }

.. icd:: Memory Search Request
   :id: ICD-10
   :links: SAD-12.3

   .. code-block:: json

      {
        "command": "memory_search",
        "request_id": "uuid",
        "payload": {
          "query": "recipe for pasta",
          "top_k": 5,
          "date_range": {
            "start": "ISO-8601",
            "end": "ISO-8601"
          }
        }
      }

.. icd:: Memory Search Response
   :id: ICD-11
   :links: FSD-14.4

   .. code-block:: json

      {
        "status": "success",
        "results": [
          {
            "conversation_id": "uuid",
            "timestamp": "ISO-8601",
            "snippet": "You asked: 'How do I make carbonara?'",
            "similarity_score": 0.89
          }
        ]
      }
~~~

**TDD (Components):**

~~~rst
.. tdd:: Component: MemoryService
   :id: TDD-8
   :links: ICD-9, SAD-12

.. tdd:: Class: MemoryService (inherits ServiceClient pattern)
   :id: TDD-8.1
   :links: TDD-8

.. tdd:: Dependencies: sentence-transformers, faiss-cpu, sqlite3
   :id: TDD-8.2
   :links: TDD-8

.. tdd:: Method: index_conversation(text: str, metadata: dict)
   :id: TDD-8.3
   :links: TDD-8

.. tdd:: Method: search_memory(query: str, top_k: int) -> List[dict]
   :id: TDD-8.4
   :links: TDD-8

.. tdd:: Internal: embedding_model (all-MiniLM-L6-v2, 384-dim)
   :id: TDD-8.5
   :links: TDD-8

.. tdd:: Internal: faiss_index (HNSW, M=16, efConstruction=200)
   :id: TDD-8.6
   :links: TDD-8

.. tdd:: Internal: sqlite_conn (conversations table + FTS5)
   :id: TDD-8.7
   :links: TDD-8

.. tdd:: Component: UI ConversationSidebar
   :id: TDD-9
   :links: FSD-14.5

.. tdd:: Class: ConversationSidebar (QWidget)
   :id: TDD-9.1
   :links: TDD-9

.. tdd:: Method: display_results(results: List[dict])
   :id: TDD-9.2
   :links: TDD-9

.. tdd:: Method: on_result_click(conversation_id: str) → load_conversation
   :id: TDD-9.3
   :links: TDD-9

.. tdd:: Signal: conversation_selected(uuid) → connects to main chat view
   :id: TDD-9.4
   :links: TDD-9
~~~

**ISP (Stubs):**

~~~python
# |ISP-9|: "Memory Service Implementation Stub"

import faiss
import sqlite3
from sentence_transformers import SentenceTransformer
from typing import List, Dict

class MemoryService(ServiceClient):
    """
    Conversation indexing and semantic search service.

    Implements
    ----------
    |TDD-8|, |FSD-14|

    Performance
    -----------
    |NFR-12.2|: Search latency <50ms for 10k entries

    Attributes
    ----------
    embedding_model : SentenceTransformer
        all-MiniLM-L6-v2 (384-dim, |TDD-8.5|)
    faiss_index : faiss.IndexHNSWFlat
        Vector index (|TDD-8.6|)
    db_conn : sqlite3.Connection
        Local conversation database (|TDD-8.7|)
    """

    def __init__(self, config_path: str, db_path: str):
        """
        Initialize memory service with embedding model and database.

        Parameters
        ----------
        config_path : str
            Path to ipc_config.yaml
        db_path : str
            Path to conversations.db (SQLite)

        Implementation Notes
        --------------------
        1. Call super().__init__("memory", config_path)
        2. Load embedding model (sentence-transformers)
        3. Initialize FAISS index or load from disk
        4. Connect to SQLite database
        5. Create tables if not exist (conversations, embeddings)

        References
        ----------
        |TDD-8.2|, |SAD-12.4|
        """
        super().__init__("memory", config_path)
        pass

    def index_conversation(self, text: str, metadata: dict) -> None:
        """
        Generate embedding and store in vector database.

        Parameters
        ----------
        text : str
            Full conversation text
        metadata : dict
            Contains conversation_id, timestamp, speaker (|ICD-9|)

        Implementation Notes
        --------------------
        1. Generate embedding: self.embedding_model.encode(text)
        2. Add to FAISS index: self.faiss_index.add(embedding)
        3. Insert into SQLite: (conversation_id, text, timestamp)
        4. Commit transaction
        5. Send log confirmation (non-blocking)

        Performance
        -----------
        - CPU-only embedding generation (|NFR-12.1|)
        - Async execution (no blocking Core) (|SAD-12.2|)

        References
        ----------
        |TDD-8.3|, |FSD-14.1|
        """
        pass

    def search_memory(self, query: str, top_k: int = 5) -> List[dict]:
        """
        Semantic search across conversation history.

        Parameters
        ----------
        query : str
            User search query
        top_k : int
            Number of results to return

        Returns
        -------
        List[dict]
            Results matching |ICD-11| schema

        Implementation Notes
        --------------------
        1. Generate query embedding
        2. FAISS search: distances, indices = index.search(embedding, top_k)
        3. Retrieve metadata from SQLite using indices
        4. Construct response per |ICD-11|
        5. Return results (sorted by similarity_score DESC)

        Performance
        -----------
        - Must complete <50ms for 10k entries (|NFR-12.2|)
        - Use HNSW parameters: M=16, efSearch=64

        References
        ----------
        |TDD-8.4|, |FSD-14.4|
        """
        pass
~~~

----------
